"""
Maria åå°æ™ºèƒ½ä»»åŠ¡
- é‚®ä»¶è‡ªåŠ¨åŒæ­¥
- æ—¥å†è‡ªåŠ¨åŒæ­¥
- æ™ºèƒ½ç›‘æ§ä¸ä¸»åŠ¨æé†’
- é‚®ä»¶ä¸Šä¸‹æ–‡è®°å¿†
- ä¸»åŠ¨ä»»åŠ¡å·¡æ£€ä¸è¿›åº¦æ±‡æŠ¥ï¼ˆæ–°å¢ï¼‰
"""
from loguru import logger
from datetime import datetime, timedelta
from app.services.email_context_service import email_context_service


async def auto_sync_emails():
    """
    åå°è‡ªåŠ¨åŒæ­¥æ‰€æœ‰é‚®ç®±è´¦æˆ·çš„é‚®ä»¶
    æ¯10åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼Œç¡®ä¿é‚®ä»¶ç¼“å­˜å§‹ç»ˆæ˜¯æœ€æ–°çš„
    """
    try:
        from app.services.multi_email_service import multi_email_service
        
        logger.info("[Mariaåå°] å¼€å§‹è‡ªåŠ¨åŒæ­¥é‚®ä»¶...")
        
        # è·å–æ‰€æœ‰æ´»è·ƒé‚®ç®±è´¦æˆ·
        accounts = await multi_email_service.get_email_accounts(active_only=True)
        
        total_new = 0
        for account in accounts:
            try:
                result = await multi_email_service.sync_account_emails(
                    account["id"], 
                    days_back=7, 
                    max_emails=50  # æ¯æ¬¡æœ€å¤šåŒæ­¥50å°
                )
                
                if result.get("success"):
                    new_count = result.get("new_count", 0)
                    total_new += new_count
                    if new_count > 0:
                        logger.info(f"[Mariaåå°] {account['name']} åŒæ­¥äº† {new_count} å°æ–°é‚®ä»¶")
                        
            except Exception as e:
                logger.error(f"[Mariaåå°] åŒæ­¥ {account['name']} å¤±è´¥: {e}")
                continue
        
        if total_new > 0:
            logger.info(f"[Mariaåå°] âœ… é‚®ä»¶åŒæ­¥å®Œæˆï¼Œå…±æ–°å¢ {total_new} å°")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡è¦é‚®ä»¶ï¼Œä¸»åŠ¨é€šçŸ¥ç”¨æˆ·
            try:
                await check_important_emails_and_notify()
            except Exception as notify_err:
                logger.warning(f"[Mariaåå°] é‡è¦é‚®ä»¶æ£€æŸ¥å¤±è´¥: {notify_err}")
        else:
            logger.info(f"[Mariaåå°] âœ… é‚®ä»¶åŒæ­¥å®Œæˆï¼Œæ²¡æœ‰æ–°é‚®ä»¶")
            
    except Exception as e:
        logger.error(f"[Mariaåå°] é‚®ä»¶è‡ªåŠ¨åŒæ­¥å¤±è´¥: {e}")


async def auto_sync_calendar():
    """
    åå°è‡ªåŠ¨åŒæ­¥æ—¥å†ï¼ˆæš‚æœªå®ç°ï¼Œé¢„ç•™æ¥å£ï¼‰
    æ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    """
    try:
        logger.info("[Mariaåå°] æ—¥å†è‡ªåŠ¨åŒæ­¥åŠŸèƒ½æš‚æœªå®ç°ï¼Œè·³è¿‡")
        # TODO: å®ç°æ—¥å†è‡ªåŠ¨åŒæ­¥
        # from app.services.caldav_service import apple_calendar
        # events = await apple_calendar.query_events(days=7)
        
    except Exception as e:
        logger.error(f"[Mariaåå°] æ—¥å†è‡ªåŠ¨åŒæ­¥å¤±è´¥: {e}")


# å·²é€šçŸ¥é‚®ä»¶ç¼“å­˜ï¼ˆé¿å…é‡å¤æé†’ï¼‰
# æ ¼å¼: {é‚®ä»¶å”¯ä¸€æ ‡è¯†: é€šçŸ¥æ—¶é—´}
_notified_emails_cache = {}
_NOTIFIED_CACHE_MAX_SIZE = 500  # æœ€å¤šç¼“å­˜500æ¡
_NOTIFIED_CACHE_EXPIRE_HOURS = 24  # 24å°æ—¶åè¿‡æœŸå¯é‡æ–°æé†’

# ========== ç”¨æˆ·å¿½ç•¥çš„é‚®ä»¶åˆ—è¡¨ï¼ˆæŒä¹…åŒ–åˆ°Redisï¼‰ ==========
IGNORED_EMAILS_REDIS_KEY = "maria:ignored_emails"


async def _get_ignored_emails() -> set:
    """ä»Redisè·å–ç”¨æˆ·å¿½ç•¥çš„é‚®ä»¶åˆ—è¡¨"""
    try:
        from app.services.cache_service import cache_service
        data = await cache_service.get(IGNORED_EMAILS_REDIS_KEY)
        if data:
            return set(data) if isinstance(data, list) else set()
    except Exception as e:
        logger.warning(f"[é‚®ä»¶å¿½ç•¥] è¯»å–å¿½ç•¥åˆ—è¡¨å¤±è´¥: {e}")
    return set()


async def _add_ignored_email(email_identifier: str) -> bool:
    """å°†é‚®ä»¶åŠ å…¥å¿½ç•¥åˆ—è¡¨ï¼ˆæ°¸ä¹…å¿½ç•¥ï¼‰
    
    email_identifier å¯ä»¥æ˜¯ï¼š
    - é‚®ä»¶ä¸»é¢˜ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
    - å‘ä»¶äººé‚®ç®±
    - å®Œæ•´é‚®ä»¶ID
    """
    try:
        from app.services.cache_service import cache_service
        ignored = await _get_ignored_emails()
        ignored.add(email_identifier.lower().strip())
        # æŒä¹…åŒ–åˆ° Redisï¼Œä¸è®¾è¿‡æœŸæ—¶é—´ï¼ˆæ°¸ä¹…å¿½ç•¥ï¼‰
        await cache_service.set(IGNORED_EMAILS_REDIS_KEY, list(ignored), ttl=None)
        logger.info(f"[é‚®ä»¶å¿½ç•¥] å·²æ·»åŠ å¿½ç•¥: {email_identifier}")
        return True
    except Exception as e:
        logger.error(f"[é‚®ä»¶å¿½ç•¥] æ·»åŠ å¤±è´¥: {e}")
        return False


async def _is_email_ignored(email: dict, account_name: str) -> bool:
    """æ£€æŸ¥é‚®ä»¶æ˜¯å¦åœ¨å¿½ç•¥åˆ—è¡¨ä¸­"""
    try:
        ignored = await _get_ignored_emails()
        if not ignored:
            return False
        
        subject = (email.get("subject", "") or "").lower()
        from_addr = (email.get("from_address", "") or "").lower()
        
        for pattern in ignored:
            # åŒ¹é…ä¸»é¢˜ï¼ˆåŒ…å«å…³é”®è¯å³å¿½ç•¥ï¼‰
            if pattern in subject:
                return True
            # åŒ¹é…å‘ä»¶äºº
            if pattern in from_addr:
                return True
        
        return False
    except Exception as e:
        logger.warning(f"[é‚®ä»¶å¿½ç•¥] æ£€æŸ¥å¤±è´¥: {e}")
        return False


async def ignore_email_by_user(identifier: str) -> dict:
    """ç”¨æˆ·æ˜ç¡®è¦æ±‚å¿½ç•¥æŸå°é‚®ä»¶/æŸç±»é‚®ä»¶
    
    è¿™æ˜¯ Maria è°ƒç”¨çš„æ¥å£ï¼Œå½“ç”¨æˆ·è¯´"ä¸å¤„ç†"ã€"å·²è¯»"ã€"è¿‡æ»¤"æ—¶è°ƒç”¨
    
    Args:
        identifier: é‚®ä»¶ä¸»é¢˜å…³é”®è¯ã€å‘ä»¶äººé‚®ç®±ç­‰
    
    Returns:
        {"success": True/False, "message": "..."}
    """
    success = await _add_ignored_email(identifier)
    if success:
        return {
            "success": True,
            "message": f"å¥½çš„ï¼Œå·²å°†åŒ…å«ã€Œ{identifier}ã€çš„é‚®ä»¶åŠ å…¥å¿½ç•¥åˆ—è¡¨ï¼Œä»¥åä¸ä¼šå†æé†’æ‚¨ã€‚"
        }
    else:
        return {
            "success": False,
            "message": "æŠ±æ­‰ï¼Œæ·»åŠ å¿½ç•¥å¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚"
        }


def _get_email_id(email: dict, account_name: str) -> str:
    """ç”Ÿæˆé‚®ä»¶å”¯ä¸€æ ‡è¯†"""
    subject = email.get("subject", "")[:50]
    from_addr = email.get("from_address", "")
    date_str = str(email.get("received_at", ""))[:10]  # åªå–æ—¥æœŸéƒ¨åˆ†
    return f"{account_name}:{from_addr}:{subject}:{date_str}"


def _is_email_notified(email_id: str) -> bool:
    """æ£€æŸ¥é‚®ä»¶æ˜¯å¦å·²é€šçŸ¥è¿‡ï¼ˆ24å°æ—¶å†…ï¼‰"""
    from datetime import datetime, timedelta
    
    if email_id not in _notified_emails_cache:
        return False
    
    notified_time = _notified_emails_cache[email_id]
    # è¶…è¿‡24å°æ—¶å¯ä»¥é‡æ–°æé†’
    if datetime.now() - notified_time > timedelta(hours=_NOTIFIED_CACHE_EXPIRE_HOURS):
        del _notified_emails_cache[email_id]
        return False
    
    return True


def _mark_email_notified(email_id: str):
    """æ ‡è®°é‚®ä»¶å·²é€šçŸ¥"""
    from datetime import datetime
    
    # æ¸…ç†è¿‡æœŸç¼“å­˜
    if len(_notified_emails_cache) > _NOTIFIED_CACHE_MAX_SIZE:
        # åˆ é™¤æœ€æ—§çš„ä¸€åŠ
        sorted_items = sorted(_notified_emails_cache.items(), key=lambda x: x[1])
        for key, _ in sorted_items[:len(sorted_items)//2]:
            del _notified_emails_cache[key]
    
    _notified_emails_cache[email_id] = datetime.now()


async def check_important_emails_and_notify():
    """
    æ£€æŸ¥é‡è¦é‚®ä»¶å¹¶ä¸»åŠ¨é€šçŸ¥ç”¨æˆ·ï¼ˆå¢å¼ºç‰ˆï¼‰
    - VIPå‘ä»¶äººï¼ˆå¯é…ç½®ï¼‰
    - åŒ…å«ç´§æ€¥å…³é”®è¯
    - å¤§é¢è®¢å•ç›¸å…³
    - å›å¤/è½¬å‘çš„é‚®ä»¶
    - å®¢æˆ·åŸŸåé‚®ä»¶
    
    æ³¨æ„ï¼šå·²é€šçŸ¥è¿‡çš„é‚®ä»¶24å°æ—¶å†…ä¸ä¼šé‡å¤æé†’
    """
    try:
        from app.services.multi_email_service import multi_email_service
        from app.api.wechat_assistant import send_text_message
        
        # è·å–æœªè¯»é‚®ä»¶æ‘˜è¦
        summary = await multi_email_service.get_unread_summary()
        
        # ç´§æ€¥å…³é”®è¯ï¼ˆä¸»é¢˜å’Œæ­£æ–‡ï¼‰
        URGENT_KEYWORDS = [
            # è‹±æ–‡
            "urgent", "asap", "important", "critical", "emergency", "deadline",
            "payment", "invoice", "order", "shipping", "delivery", "tracking",
            "quote", "quotation", "inquiry", "rfq", "po ", "purchase order",
            "customs", "clearance", "delay",
            # ä¸­æ–‡
            "ç´§æ€¥", "é‡è¦", "æ€¥", "è®¢å•", "ä»˜æ¬¾", "å‘ç¥¨", "æŠ¥ä»·", "è¯¢ç›˜",
            "è´§è¿", "ç‰©æµ", "æ¸…å…³", "æµ·å…³", "å»¶è¯¯", "å‚¬", "å°½å¿«",
        ]
        
        # VIPå‘ä»¶äººåŸŸåï¼ˆå¯æ‰©å±•ï¼‰
        VIP_DOMAINS = [
            # å¤§å®¢æˆ·åŸŸå
            "amazon.com", "alibaba.com", "dhl.com", "fedex.com", "ups.com",
        ]
        
        important_emails = []
        
        for account in summary.get("accounts", []):
            for email in account.get("recent_emails", [])[:10]:  # æ£€æŸ¥æœ€æ–°10å°
                subject = (email.get("subject", "") or "").lower()
                from_addr = (email.get("from_address", "") or "").lower()
                body_preview = (email.get("body_preview", "") or "").lower()
                
                is_important = False
                reason = ""
                
                # è§„åˆ™1ï¼šç´§æ€¥å…³é”®è¯ï¼ˆä¸»é¢˜ä¼˜å…ˆï¼‰
                for kw in URGENT_KEYWORDS:
                    if kw in subject:
                        is_important = True
                        reason = f"ä¸»é¢˜å«ã€Œ{kw}ã€"
                        break
                    if kw in body_preview:
                        is_important = True
                        reason = f"æ­£æ–‡å«ã€Œ{kw}ã€"
                        break
                
                # è§„åˆ™2ï¼šVIPå‘ä»¶äººåŸŸå
                if not is_important:
                    for domain in VIP_DOMAINS:
                        if domain in from_addr:
                            is_important = True
                            reason = f"æ¥è‡ª {domain}"
                            break
                
                # è§„åˆ™3ï¼šå›å¤é‚®ä»¶ï¼ˆå¯èƒ½æ˜¯å®¢æˆ·å›å¤ï¼‰
                if not is_important and (subject.startswith("re:") or subject.startswith("å›å¤:")):
                    is_important = True
                    reason = "å®¢æˆ·å›å¤"
                
                if is_important:
                    # æ£€æŸ¥æ˜¯å¦åœ¨ç”¨æˆ·å¿½ç•¥åˆ—è¡¨ä¸­ï¼ˆæ°¸ä¹…å¿½ç•¥ï¼‰
                    if await _is_email_ignored(email, account.get("name", "")):
                        continue  # ç”¨æˆ·å·²æ˜ç¡®è¯´ä¸å¤„ç†ï¼Œæ°¸ä¹…è·³è¿‡
                    
                    # æ£€æŸ¥æ˜¯å¦å·²é€šçŸ¥è¿‡ï¼ˆ24å°æ—¶å†…é¿å…é‡å¤æé†’ï¼‰
                    email_id = _get_email_id(email, account.get("name", ""))
                    if _is_email_notified(email_id):
                        continue  # è·³è¿‡å·²é€šçŸ¥çš„é‚®ä»¶
                    
                    important_emails.append({
                        "subject": email.get("subject", "(æ— ä¸»é¢˜)"),
                        "from": email.get("from_name") or email.get("from_address"),
                        "account": account.get("name"),
                        "reason": reason,
                        "preview": (email.get("body_preview", "") or "")[:60],
                        "_email_id": email_id,  # ä¿å­˜IDç”¨äºæ ‡è®°
                    })
        
        # å»é‡ï¼ˆåŒä¸€ä¸»é¢˜åªä¿ç•™ä¸€å°ï¼‰
        seen_subjects = set()
        unique_emails = []
        for e in important_emails:
            subj_key = e["subject"][:30].lower()
            if subj_key not in seen_subjects:
                seen_subjects.add(subj_key)
                unique_emails.append(e)
        
        # å¦‚æœæœ‰é‡è¦é‚®ä»¶ï¼Œå‘é€é€šçŸ¥
        if unique_emails:
            message = f"ğŸ“¬ éƒ‘æ€»ï¼Œæ‚¨æœ‰ {len(unique_emails)} å°é‡è¦é‚®ä»¶ï¼š\n\n"
            for i, email in enumerate(unique_emails[:5], 1):  # æœ€å¤šé€šçŸ¥5å°
                message += f"{i}. ã€{email['account']}ã€‘{email['from']}\n"
                message += f"   ğŸ“Œ {email['subject'][:40]}\n"
                if email.get("preview"):
                    message += f"   ğŸ’¬ {email['preview']}...\n"
                message += f"   ğŸ”– {email['reason']}\n\n"
            
            if len(unique_emails) > 5:
                message += f"è¿˜æœ‰ {len(unique_emails) - 5} å°ï¼Œè¯·æŸ¥çœ‹é‚®ç®±ã€‚\n"
            
            message += "éœ€è¦æˆ‘å¸®æ‚¨å¤„ç†æˆ–å›å¤å—ï¼Ÿ"
            
            # å‘é€åˆ°ä¼ä¸šå¾®ä¿¡
            await send_text_message("Frank.Z", message)
            
            # æ ‡è®°è¿™äº›é‚®ä»¶ä¸ºå·²é€šçŸ¥ï¼ˆé¿å…é‡å¤æé†’ï¼‰
            for email in unique_emails:
                if "_email_id" in email:
                    _mark_email_notified(email["_email_id"])
            
            logger.info(f"[Mariaåå°] âœ… å·²é€šçŸ¥ç”¨æˆ· {len(unique_emails)} å°é‡è¦é‚®ä»¶")
            
    except Exception as e:
        import traceback
        logger.error(f"[Mariaåå°] æ£€æŸ¥é‡è¦é‚®ä»¶å¤±è´¥: {e}")
        logger.error(traceback.format_exc())


async def maria_morning_brief():
    """
    Maria æ—©é—´æ™ºèƒ½ç®€æŠ¥ï¼ˆæ¯å¤©9:00ï¼‰
    
    åŒ…å«ï¼š
    1. ä»Šæ—¥æ—¥ç¨‹æ¦‚è§ˆ + å†²çªæ£€æµ‹
    2. AIå›¢é˜Ÿä»»åŠ¡è¿›åº¦ï¼ˆè¿›è¡Œä¸­/å¾…å¤„ç†ï¼‰
    3. æœªè¯»é‚®ä»¶ç»Ÿè®¡
    4. ä¸»åŠ¨å»ºè®®ï¼ˆåŸºäºæ—¥ç¨‹å’Œä»»åŠ¡åˆ†æï¼‰
    """
    try:
        from app.api.wechat_assistant import send_text_message
        from app.models.database import AsyncSessionLocal
        from sqlalchemy import text
        import pytz
        
        logger.info("[Mariaåå°] ç”Ÿæˆæ—©é—´æ™ºèƒ½ç®€æŠ¥...")
        
        CHINA_TZ = pytz.timezone('Asia/Shanghai')
        now = datetime.now(CHINA_TZ)
        today_str = now.strftime("%Y-%m-%d")
        weekday_names = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"]
        weekday = weekday_names[now.weekday()]
        
        brief_parts = [f"éƒ‘æ€»ï¼Œæ—©ä¸Šå¥½ï¼ä»Šå¤©æ˜¯{now.month}æœˆ{now.day}æ—¥ {weekday}ã€‚\n"]
        suggestions = []  # ä¸»åŠ¨å»ºè®®æ”¶é›†
        
        # ===== 1. ä»Šæ—¥æ—¥ç¨‹ + å†²çªæ£€æµ‹ =====
        try:
            async with AsyncSessionLocal() as db:
                result = await db.execute(
                    text("""
                        SELECT title, start_time, end_time, location, priority
                        FROM assistant_schedules
                        WHERE DATE(start_time) = :today
                        AND is_completed = FALSE
                        ORDER BY start_time ASC
                    """),
                    {"today": today_str}
                )
                schedules = result.fetchall()
            
            if schedules:
                brief_parts.append(f"ä»Šæ—¥æ—¥ç¨‹ï¼ˆ{len(schedules)}é¡¹ï¼‰ï¼š")
                
                prev_end = None
                for s in schedules:
                    title, start, end_time, location, priority = s[0], s[1], s[2], s[3], s[4]
                    
                    if start and start.tzinfo is None:
                        start = pytz.UTC.localize(start)
                    china_start = start.astimezone(CHINA_TZ) if start else None
                    
                    time_str = china_start.strftime("%H:%M") if china_start else "å…¨å¤©"
                    loc_str = f" - {location}" if location else ""
                    priority_icon = {"urgent": "!!", "high": "!"}.get(priority, "")
                    
                    brief_parts.append(f"  {time_str} {priority_icon}{title}{loc_str}")
                    
                    # å†²çªæ£€æµ‹ï¼šå½“å‰æ—¥ç¨‹å¼€å§‹æ—¶é—´æ—©äºä¸Šä¸€ä¸ªæ—¥ç¨‹ç»“æŸæ—¶é—´
                    if prev_end and china_start and china_start < prev_end:
                        suggestions.append(f"æ—¥ç¨‹å†²çªï¼šã€Œ{title}ã€ä¸å‰ä¸€ä¸ªæ—¥ç¨‹æ—¶é—´é‡å ï¼Œå»ºè®®è°ƒæ•´")
                    
                    if end_time:
                        if end_time.tzinfo is None:
                            end_time = pytz.UTC.localize(end_time)
                        prev_end = end_time.astimezone(CHINA_TZ)
                    elif china_start:
                        # é»˜è®¤å‡è®¾1å°æ—¶
                        from datetime import timedelta
                        prev_end = china_start + timedelta(hours=1)
                
                brief_parts.append("")
            else:
                brief_parts.append("ä»Šå¤©æ²¡æœ‰æ—¥ç¨‹å®‰æ’ï¼Œå¯ä»¥ä¸“æ³¨å¤„ç†é¡¹ç›®ã€‚\n")
        except Exception as e:
            logger.warning(f"[Mariaç®€æŠ¥] æ—¥ç¨‹æŸ¥è¯¢å¤±è´¥: {e}")
        
        # ===== 2. AIå›¢é˜Ÿä»»åŠ¡è¿›åº¦ =====
        try:
            async with AsyncSessionLocal() as db:
                # è¿›è¡Œä¸­çš„ä»»åŠ¡
                result = await db.execute(
                    text("""
                        SELECT agent_type, COUNT(*) 
                        FROM ai_tasks 
                        WHERE status = 'pending' 
                        GROUP BY agent_type
                    """)
                )
                pending_tasks = result.fetchall()
                
                # æ˜¨æ—¥å®Œæˆçš„ä»»åŠ¡
                result2 = await db.execute(
                    text("""
                        SELECT COUNT(*) FROM ai_tasks 
                        WHERE status = 'completed' 
                        AND completed_at >= CURRENT_DATE - INTERVAL '1 day'
                        AND completed_at < CURRENT_DATE
                    """)
                )
                yesterday_completed = result2.fetchone()[0]
                
                # å¤±è´¥çš„ä»»åŠ¡
                result3 = await db.execute(
                    text("""
                        SELECT COUNT(*) FROM ai_tasks 
                        WHERE status = 'failed' 
                        AND created_at >= CURRENT_DATE - INTERVAL '1 day'
                    """)
                )
                recent_failed = result3.fetchone()[0]
            
            agent_names = {
                "coordinator": "å°è°ƒ", "video_creator": "å°å½±",
                "copywriter": "å°æ–‡", "sales": "å°é”€",
                "follow": "å°è·Ÿ", "analyst": "å°æ",
                "lead_hunter": "å°çŒ", "analyst2": "å°æ2",
                "eu_customs_monitor": "å°æ¬§é—´è°",
            }
            
            if pending_tasks:
                total_pending = sum(row[1] for row in pending_tasks)
                brief_parts.append(f"AIå›¢é˜Ÿï¼š{total_pending}ä¸ªä»»åŠ¡å¾…å¤„ç†")
                for row in pending_tasks:
                    name = agent_names.get(row[0], row[0])
                    brief_parts.append(f"  {name}: {row[1]}ä¸ª")
                brief_parts.append("")
                
                if total_pending > 10:
                    suggestions.append(f"ä»»åŠ¡ç§¯å‹ï¼šå½“å‰æœ‰{total_pending}ä¸ªå¾…å¤„ç†ä»»åŠ¡ï¼Œå»ºè®®å…³æ³¨é˜Ÿåˆ—æ¶ˆåŒ–é€Ÿåº¦")
            
            if yesterday_completed > 0:
                brief_parts.append(f"æ˜¨æ—¥å®Œæˆï¼š{yesterday_completed}ä¸ªä»»åŠ¡")
            
            if recent_failed > 0:
                brief_parts.append(f"è¿‘æœŸå¤±è´¥ï¼š{recent_failed}ä¸ªä»»åŠ¡")
                suggestions.append(f"æœ‰{recent_failed}ä¸ªä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œå»ºè®®æŸ¥çœ‹åŸå› ")
            
            brief_parts.append("")
        except Exception as e:
            logger.warning(f"[Mariaç®€æŠ¥] ä»»åŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
        
        # ===== 3. æœªè¯»é‚®ä»¶ =====
        try:
            from app.services.multi_email_service import multi_email_service
            email_summary = await multi_email_service.get_unread_summary()
            total_unread = email_summary.get("total_unread", 0)
            
            if total_unread > 0:
                brief_parts.append(f"æœªè¯»é‚®ä»¶ï¼š{total_unread}å°")
                for account in email_summary.get("accounts", [])[:3]:
                    if account.get("unread_count", 0) > 0:
                        brief_parts.append(f"  {account['name']}: {account['unread_count']}å°")
                brief_parts.append("")
                
                if total_unread > 20:
                    suggestions.append(f"é‚®ç®±ç§¯å‹ï¼š{total_unread}å°æœªè¯»é‚®ä»¶ï¼Œå»ºè®®æŠ½ç©ºå¤„ç†")
            else:
                brief_parts.append("é‚®ç®±æ¸…å‡€ï¼Œæ²¡æœ‰æœªè¯»é‚®ä»¶ã€‚\n")
        except Exception as e:
            logger.warning(f"[Mariaç®€æŠ¥] é‚®ä»¶ç»Ÿè®¡å¤±è´¥: {e}")
        
        # ===== 4. ä¸»åŠ¨å»ºè®® =====
        if suggestions:
            brief_parts.append("æˆ‘çš„å»ºè®®ï¼š")
            for i, s in enumerate(suggestions, 1):
                brief_parts.append(f"  {i}. {s}")
            brief_parts.append("")
        
        brief_parts.append("æœ‰éœ€è¦éšæ—¶å«æˆ‘ã€‚")
        
        # å‘é€ç®€æŠ¥
        brief = "\n".join(brief_parts)
        await send_text_message("Frank.Z", brief)
        logger.info("[Mariaåå°] æ—©é—´æ™ºèƒ½ç®€æŠ¥å·²å‘é€")
        
    except Exception as e:
        logger.error(f"[Mariaåå°] æ—©é—´ç®€æŠ¥ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


async def check_maria_inbox_attachments():
    """
    æ£€æŸ¥ Maria ä¸“å±é‚®ç®±ä¸­å¸¦é™„ä»¶çš„é‚®ä»¶
    è‡ªåŠ¨ä¸‹è½½é™„ä»¶å¹¶åˆ†æå†…å®¹ï¼Œé€šçŸ¥è€æ¿
    
    æ¯10åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    """
    try:
        from app.services.multi_email_service import multi_email_service
        from app.api.wechat_assistant import send_text_message
        from app.services.document_service import document_service
        from app.core.llm import chat_completion
        
        logger.info("[Mariaé‚®ç®±] æ£€æŸ¥æ”¶ä»¶ç®±é™„ä»¶...")
        
        # è·å– Maria é‚®ç®±æœ€è¿‘24å°æ—¶çš„æœªè¯»é‚®ä»¶
        emails = await multi_email_service.get_maria_inbox_emails(
            hours=24,
            unread_only=True
        )
        
        if not emails:
            logger.debug("[Mariaé‚®ç®±] æ²¡æœ‰æ–°é‚®ä»¶")
            return
        
        # ç­›é€‰å¸¦é™„ä»¶çš„é‚®ä»¶
        emails_with_attachments = [e for e in emails if e.get("has_attachments")]
        
        if not emails_with_attachments:
            logger.debug("[Mariaé‚®ç®±] æ²¡æœ‰å¸¦é™„ä»¶çš„æ–°é‚®ä»¶")
            return
        
        logger.info(f"[Mariaé‚®ç®±] å‘ç° {len(emails_with_attachments)} å°å¸¦é™„ä»¶çš„é‚®ä»¶")
        
        for email in emails_with_attachments:
            try:
                email_id = email["id"]
                subject = email.get("subject", "(æ— ä¸»é¢˜)")
                from_name = email.get("from_name") or email.get("from_address", "æœªçŸ¥å‘ä»¶äºº")
                attachment_names = email.get("attachment_names", [])
                
                # å…ˆé€šçŸ¥æ”¶åˆ°é‚®ä»¶
                await send_text_message(
                    "Frank.Z",
                    f"ğŸ“§ æ”¶åˆ°ä¸€å°å¸¦é™„ä»¶çš„é‚®ä»¶ï¼š\n\n"
                    f"ğŸ“Œ ä¸»é¢˜ï¼š{subject}\n"
                    f"ğŸ‘¤ å‘ä»¶äººï¼š{from_name}\n"
                    f"ğŸ“ é™„ä»¶ï¼š{', '.join(attachment_names)}\n\n"
                    f"æ­£åœ¨ä¸‹è½½å¹¶åˆ†æ..."
                )
                
                # ä¸‹è½½é™„ä»¶
                download_result = await multi_email_service.download_attachments(
                    email_id,
                    save_dir="/tmp/maria_attachments"
                )
                
                if not download_result.get("success"):
                    await send_text_message(
                        "Frank.Z",
                        f"âš ï¸ é™„ä»¶ä¸‹è½½å¤±è´¥ï¼š{download_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                    )
                    continue
                
                attachments = download_result.get("attachments", [])
                
                # åˆ†ææ¯ä¸ªé™„ä»¶
                for att in attachments:
                    filename = att.get("filename", "æœªçŸ¥æ–‡ä»¶")
                    filepath = att.get("path")
                    content_type = att.get("content_type", "")
                    
                    # åªåˆ†ææ–‡æ¡£ç±»å‹
                    supported_types = [
                        "application/pdf", "application/msword",
                        "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                        "text/plain"
                    ]
                    
                    if content_type not in supported_types and not filename.lower().endswith(('.pdf', '.doc', '.docx', '.txt')):
                        await send_text_message(
                            "Frank.Z",
                            f"ğŸ“ é™„ä»¶ã€Œ{filename}ã€ä¸æ˜¯æ–‡æ¡£ç±»å‹ï¼Œæš‚ä¸æ”¯æŒåˆ†æã€‚"
                        )
                        continue
                    
                    # è¯»å–æ–‡æ¡£å†…å®¹
                    doc_result = await document_service.read_document(filepath, filename)
                    
                    if not doc_result.get("success"):
                        await send_text_message(
                            "Frank.Z",
                            f"âš ï¸ æ— æ³•è¯»å–ã€Œ{filename}ã€ï¼š{doc_result.get('error', 'æ ¼å¼ä¸æ”¯æŒ')}"
                        )
                        continue
                    
                    content = doc_result.get("content", "")
                    word_count = len(content)
                    
                    if word_count < 50:
                        await send_text_message(
                            "Frank.Z",
                            f"ğŸ“ é™„ä»¶ã€Œ{filename}ã€å†…å®¹è¿‡å°‘ï¼ˆ{word_count}å­—ï¼‰ï¼Œè·³è¿‡åˆ†æã€‚"
                        )
                        continue
                    
                    # åˆ¤æ–­æ–‡æ¡£ç±»å‹å¹¶æ„å»ºåˆ†ææç¤ºè¯
                    filename_lower = filename.lower()
                    is_contract = any(kw in filename_lower for kw in ["åˆåŒ", "åè®®", "contract", "agreement"])
                    is_finance = any(kw in filename_lower for kw in ["å‘ç¥¨", "invoice", "è´¢åŠ¡", "æŠ¥è¡¨", "è´¦å•"])
                    is_logistics = any(kw in filename_lower for kw in ["è¿è¾“", "ç‰©æµ", "logistics", "shipping", "æå•", "æŠ¥å…³"])
                    
                    if is_contract:
                        prompt = f"""ã€æ³•å¾‹é¡¾é—®æ¨¡å¼ã€‘è€æ¿é€šè¿‡é‚®ä»¶å‘æ¥ä¸€ä»½åˆåŒ/åè®®ï¼Œè¯·ä»¥èµ„æ·±æ³•åŠ¡çš„èº«ä»½è¿›è¡Œä¸“ä¸šåˆ†æï¼š

ğŸ“„ æ–‡ä»¶åï¼š{filename}
ğŸ“§ æ¥è‡ªï¼š{from_name}
ğŸ“Œ é‚®ä»¶ä¸»é¢˜ï¼š{subject}

ğŸ“ æ–‡æ¡£å†…å®¹ï¼š
{content[:15000]}

---
è¯·åˆ†æï¼š
1. åˆåŒç±»å‹å’Œä¸»è¦æ¡æ¬¾
2. å¯¹æˆ‘æ–¹çš„ä¸»è¦æƒåˆ©å’Œä¹‰åŠ¡
3. æ½œåœ¨é£é™©ç‚¹ï¼ˆçº¢æ——æ¡æ¬¾ï¼‰
4. å»ºè®®çš„ä¿®æ”¹æˆ–è°ˆåˆ¤è¦ç‚¹
5. æ€»ä½“è¯„ä¼°ï¼ˆæ˜¯å¦å»ºè®®ç­¾ç½²ï¼‰"""
                    elif is_finance:
                        prompt = f"""ã€è´¢åŠ¡åˆ†ææ¨¡å¼ã€‘è€æ¿é€šè¿‡é‚®ä»¶å‘æ¥ä¸€ä»½è´¢åŠ¡æ–‡æ¡£ï¼Œè¯·ä»¥ä¸“ä¸šä¼šè®¡çš„èº«ä»½è¿›è¡Œåˆ†æï¼š

ğŸ“„ æ–‡ä»¶åï¼š{filename}
ğŸ“§ æ¥è‡ªï¼š{from_name}
ğŸ“Œ é‚®ä»¶ä¸»é¢˜ï¼š{subject}

ğŸ“ æ–‡æ¡£å†…å®¹ï¼š
{content[:15000]}

---
è¯·åˆ†æï¼š
1. æ–‡æ¡£ç±»å‹å’Œä¸»è¦å†…å®¹
2. å…³é”®æ•°æ®æ‘˜è¦
3. éœ€è¦æ³¨æ„çš„äº‹é¡¹
4. å»ºè®®çš„å¤„ç†æ–¹å¼"""
                    elif is_logistics:
                        prompt = f"""ã€è·¨å¢ƒè´¸æ˜“ä¸“å®¶æ¨¡å¼ã€‘è€æ¿é€šè¿‡é‚®ä»¶å‘æ¥ä¸€ä»½ç‰©æµ/è´¸æ˜“æ–‡æ¡£ï¼Œè¯·ä»¥å›½é™…è´¸æ˜“ä¸“å®¶çš„èº«ä»½åˆ†æï¼š

ğŸ“„ æ–‡ä»¶åï¼š{filename}
ğŸ“§ æ¥è‡ªï¼š{from_name}
ğŸ“Œ é‚®ä»¶ä¸»é¢˜ï¼š{subject}

ğŸ“ æ–‡æ¡£å†…å®¹ï¼š
{content[:15000]}

---
è¯·åˆ†æï¼š
1. æ–‡æ¡£ç±»å‹å’Œå…³é”®ä¿¡æ¯
2. è¿è¾“/è´¸æ˜“æ¡æ¬¾åˆ†æ
3. æ½œåœ¨é£é™©å’Œæ³¨æ„äº‹é¡¹
4. åç»­éœ€è¦è·Ÿè¿›çš„äº‹é¡¹"""
                    else:
                        prompt = f"""è€æ¿é€šè¿‡é‚®ä»¶å‘æ¥ä¸€ä»½æ–‡æ¡£ï¼Œè¯·å¸®å¿™é˜…è¯»å¹¶åˆ†æï¼š

ğŸ“„ æ–‡ä»¶åï¼š{filename}
ğŸ“§ æ¥è‡ªï¼š{from_name}
ğŸ“Œ é‚®ä»¶ä¸»é¢˜ï¼š{subject}

ğŸ“ æ–‡æ¡£å†…å®¹ï¼š
{content[:15000]}

---
è¯·åˆ†æï¼š
1. æ–‡æ¡£çš„ä¸»è¦å†…å®¹å’Œç›®çš„
2. å…³é”®ä¿¡æ¯æ‘˜è¦
3. éœ€è¦è€æ¿å…³æ³¨æˆ–å†³ç­–çš„äº‹é¡¹
4. å»ºè®®çš„å¤„ç†æ–¹å¼"""
                    
                    # è°ƒç”¨ LLM åˆ†æï¼ˆæˆæœ¬ä¼˜åŒ–ï¼šä¼˜å…ˆä¾¿å®œæ¨¡å‹ï¼‰
                    import asyncio
                    
                    # æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©æœ€ä¼˜æ¨¡å‹ï¼ˆä¼˜å…ˆä¾¿å®œçš„ï¼‰
                    if is_contract:
                        model_preference = "legal"  # æ³•å¾‹åˆ†æ â†’ DeepSeekï¼ˆä¾¿å®œå¤Ÿç”¨ï¼‰
                    elif is_finance:
                        model_preference = "finance"  # è´¢åŠ¡åˆ†æ â†’ DeepSeek
                    elif is_logistics:
                        model_preference = "reasoning"  # ç‰©æµåˆ†æ â†’ DeepSeek
                    else:
                        model_preference = None  # é€šç”¨ä»»åŠ¡ â†’ Qwen-Maxï¼ˆæœ€ä¾¿å®œï¼‰
                    
                    try:
                        response = await asyncio.wait_for(
                            chat_completion(
                                messages=[{"role": "user", "content": prompt}],
                                model_preference=model_preference,  # åšå£«åçº§æ™ºèƒ½è·¯ç”±
                                use_advanced=True  # å¤‡ç”¨ï¼šé«˜çº§æ¨¡å‹
                            ),
                            timeout=120  # 2åˆ†é’Ÿè¶…æ—¶
                        )
                        
                        # å¤„ç†è¿”å›ç»“æœï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸ï¼‰
                        if isinstance(response, str):
                            analysis = response
                        elif isinstance(response, dict):
                            analysis = response.get("content", str(response))
                        else:
                            analysis = str(response)
                        
                        # å‘é€åˆ†æç»“æœ
                        await send_text_message(
                            "Frank.Z",
                            f"ğŸ“„ **{filename}** åˆ†æå®Œæˆï¼ˆ{word_count}å­—ï¼‰\n\n{analysis}"
                        )
                        
                        # ä¿å­˜é‚®ä»¶ä¸Šä¸‹æ–‡ï¼ˆè®©Mariaè®°ä½è¿™å°é‚®ä»¶ï¼Œä»¥ä¾¿ç”¨æˆ·åç»­å¼•ç”¨ï¼‰
                        doc_type_map = {
                            True: "contract",  # is_contract
                        }
                        if is_contract:
                            saved_doc_type = "contract"
                        elif is_finance:
                            saved_doc_type = "invoice"
                        elif is_logistics:
                            saved_doc_type = "logistics"
                        else:
                            saved_doc_type = "general"
                        
                        await email_context_service.save_email_context(
                            user_id="Frank.Z",  # é»˜è®¤è€æ¿ID
                            email_id=email_id,
                            subject=subject,
                            from_address=from_addr,
                            from_name=from_name,
                            attachment_name=filename,
                            attachment_content=content,
                            analysis_result=analysis,
                            doc_type=saved_doc_type
                        )
                        logger.info(f"[Mariaé‚®ç®±] å·²ä¿å­˜é‚®ä»¶ä¸Šä¸‹æ–‡: {filename} (type={saved_doc_type})")
                        
                    except asyncio.TimeoutError:
                        await send_text_message(
                            "Frank.Z",
                            f"âš ï¸ åˆ†æã€Œ{filename}ã€è¶…æ—¶ï¼Œæ–‡æ¡£å¯èƒ½å¤ªé•¿ã€‚æ‚¨å¯ä»¥ç›´æ¥å›å¤è®©æˆ‘é‡è¯•ã€‚"
                        )
                    except Exception as llm_err:
                        logger.error(f"[Mariaé‚®ç®±] LLM åˆ†æå¤±è´¥: {llm_err}")
                        await send_text_message(
                            "Frank.Z",
                            f"âš ï¸ åˆ†æã€Œ{filename}ã€æ—¶å‡ºé”™ï¼š{str(llm_err)[:100]}"
                        )
                
                # æ ‡è®°é‚®ä»¶å·²è¯»
                await multi_email_service.mark_email_read(email_id)
                
            except Exception as email_err:
                logger.error(f"[Mariaé‚®ç®±] å¤„ç†é‚®ä»¶å¤±è´¥: {email_err}")
                import traceback
                logger.error(traceback.format_exc())
        
        logger.info(f"[Mariaé‚®ç®±] å¤„ç†å®Œæˆ")
        
    except Exception as e:
        logger.error(f"[Mariaé‚®ç®±] æ£€æŸ¥é™„ä»¶å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


async def maria_proactive_task_check():
    """
    Maria ä¸»åŠ¨ä»»åŠ¡å·¡æ£€ï¼ˆæ¯2å°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰
    
    åŠŸèƒ½ï¼š
    1. æ£€æŸ¥AIå›¢é˜Ÿä»»åŠ¡ç§¯å‹æƒ…å†µ
    2. æ£€æŸ¥é•¿æ—¶é—´æœªå®Œæˆçš„ä»»åŠ¡
    3. æ£€æŸ¥å¤±è´¥ç‡å¼‚å¸¸çš„å‘˜å·¥
    4. ä¸»åŠ¨å‘è€æ¿æ±‡æŠ¥é—®é¢˜å’Œå»ºè®®
    """
    try:
        from app.api.wechat_assistant import send_text_message
        from app.models.database import AsyncSessionLocal
        from sqlalchemy import text
        import pytz
        
        logger.info("[Mariaå·¡æ£€] å¼€å§‹ä¸»åŠ¨ä»»åŠ¡å·¡æ£€...")
        
        CHINA_TZ = pytz.timezone('Asia/Shanghai')
        now = datetime.now(CHINA_TZ)
        
        issues = []  # å‘ç°çš„é—®é¢˜
        suggestions = []  # å»ºè®®
        
        agent_names = {
            "coordinator": "å°è°ƒ", "video_creator": "å°å½±",
            "copywriter": "å°æ–‡", "sales": "å°é”€",
            "follow": "å°è·Ÿ", "analyst": "å°æ",
            "lead_hunter": "å°çŒ", "analyst2": "å°æ2",
            "eu_customs_monitor": "å°æ¬§é—´è°",
        }
        
        async with AsyncSessionLocal() as db:
            # ===== 1. æ£€æŸ¥ä»»åŠ¡ç§¯å‹ =====
            result = await db.execute(
                text("""
                    SELECT agent_type, COUNT(*) as cnt
                    FROM ai_tasks 
                    WHERE status = 'pending' 
                    GROUP BY agent_type
                    HAVING COUNT(*) > 5
                """)
            )
            backlog = result.fetchall()
            
            for row in backlog:
                agent_type, count = row[0], row[1]
                agent_name = agent_names.get(agent_type, agent_type)
                issues.append(f"{agent_name} æœ‰ {count} ä¸ªä»»åŠ¡ç§¯å‹")
            
            # ===== 2. æ£€æŸ¥é•¿æ—¶é—´æœªå®Œæˆçš„ä»»åŠ¡ï¼ˆè¶…è¿‡24å°æ—¶ï¼‰ =====
            result = await db.execute(
                text("""
                    SELECT agent_type, task_description, created_at
                    FROM ai_tasks 
                    WHERE status = 'pending'
                    AND created_at < NOW() - INTERVAL '24 hours'
                    ORDER BY created_at ASC
                    LIMIT 5
                """)
            )
            stale_tasks = result.fetchall()
            
            if stale_tasks:
                issues.append(f"æœ‰ {len(stale_tasks)} ä¸ªä»»åŠ¡è¶…è¿‡24å°æ—¶æœªå®Œæˆ")
                for task in stale_tasks[:3]:
                    agent_name = agent_names.get(task[0], task[0])
                    desc = (task[1] or "")[:30]
                    issues.append(f"  - {agent_name}: {desc}...")
            
            # ===== 3. æ£€æŸ¥æœ€è¿‘24å°æ—¶å¤±è´¥ç‡ =====
            result = await db.execute(
                text("""
                    SELECT agent_type,
                           COUNT(*) FILTER (WHERE status = 'failed') as failed,
                           COUNT(*) as total
                    FROM ai_tasks 
                    WHERE created_at > NOW() - INTERVAL '24 hours'
                    GROUP BY agent_type
                    HAVING COUNT(*) > 3 AND COUNT(*) FILTER (WHERE status = 'failed') > 0
                """)
            )
            failure_stats = result.fetchall()
            
            for row in failure_stats:
                agent_type, failed, total = row[0], row[1], row[2]
                failure_rate = (failed / total) * 100
                if failure_rate > 30:  # å¤±è´¥ç‡è¶…è¿‡30%
                    agent_name = agent_names.get(agent_type, agent_type)
                    issues.append(f"{agent_name} å¤±è´¥ç‡ {failure_rate:.0f}%ï¼ˆ{failed}/{total}ä¸ªä»»åŠ¡ï¼‰")
                    suggestions.append(f"å»ºè®®æ£€æŸ¥ {agent_name} çš„é…ç½®æˆ–æ—¥å¿—")
            
            # ===== 3.5. æ˜¾ç¤ºæœ€è¿‘å¤±è´¥ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰ =====
            result = await db.execute(
                text("""
                    SELECT 
                        agent_type,
                        task_description,
                        error_message,
                        completed_at,
                        id
                    FROM ai_tasks 
                    WHERE status = 'failed'
                    AND completed_at > NOW() - INTERVAL '6 hours'
                    ORDER BY completed_at DESC
                    LIMIT 5
                """)
            )
            recent_failures = result.fetchall()
            
            if recent_failures:
                issues.append(f"\nâš ï¸ æœ€è¿‘6å°æ—¶å¤±è´¥çš„ä»»åŠ¡è¯¦æƒ…ï¼š")
                for task in recent_failures:
                    agent_type, desc, error, completed_at, task_id = task
                    agent_name = agent_names.get(agent_type, agent_type)
                    desc_short = (desc or "æœªçŸ¥ä»»åŠ¡")[:40]
                    error_short = (error or "æœªçŸ¥é”™è¯¯")[:60]
                    time_str = completed_at.strftime("%H:%M") if completed_at else "?"
                    issues.append(f"  [{time_str}] {agent_name}: {desc_short}")
                    issues.append(f"      âŒ åŸå› : {error_short}")
                
                suggestions.append("å¯ä»¥è®©æˆ‘é‡è¯•å¤±è´¥çš„ä»»åŠ¡ï¼Œæˆ–è€…æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—")
            
            # ===== 4. æ£€æŸ¥ä»Šæ—¥å¾…åŠå®Œæˆæƒ…å†µ =====
            result = await db.execute(
                text("""
                    SELECT COUNT(*) as pending
                    FROM assistant_schedules
                    WHERE DATE(start_time) = CURRENT_DATE
                    AND is_completed = FALSE
                """)
            )
            pending_schedules = result.fetchone()[0]
            
            if pending_schedules > 0 and now.hour >= 17:  # ä¸‹åˆ5ç‚¹åè¿˜æœ‰æœªå®Œæˆçš„æ—¥ç¨‹
                issues.append(f"ä»Šæ—¥è¿˜æœ‰ {pending_schedules} ä¸ªæ—¥ç¨‹/å¾…åŠæœªå®Œæˆ")
        
        # ===== 5. å¦‚æœæœ‰é—®é¢˜ï¼Œä¸»åŠ¨æ±‡æŠ¥ =====
        if issues:
            message = f"éƒ‘æ€»ï¼ŒMaria ä¸»åŠ¨å·¡æ£€å‘ç°ä»¥ä¸‹é—®é¢˜ï¼š\n\n"
            
            for i, issue in enumerate(issues, 1):
                message += f"{i}. {issue}\n"
            
            if suggestions:
                message += "\næˆ‘çš„å»ºè®®ï¼š\n"
                for s in suggestions:
                    message += f"â€¢ {s}\n"
            
            message += "\néœ€è¦æˆ‘å¤„ç†å“ªä¸ªé—®é¢˜å—ï¼Ÿ"
            
            await send_text_message("Frank.Z", message)
            logger.info(f"[Mariaå·¡æ£€] å·²ä¸»åŠ¨æ±‡æŠ¥ {len(issues)} ä¸ªé—®é¢˜")
        else:
            logger.info("[Mariaå·¡æ£€] ä¸€åˆ‡æ­£å¸¸ï¼Œæ— éœ€æ±‡æŠ¥")
        
    except Exception as e:
        logger.error(f"[Mariaå·¡æ£€] ä¸»åŠ¨å·¡æ£€å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


async def maria_evening_summary():
    """
    Maria æ™šé—´å·¥ä½œæ€»ç»“ï¼ˆæ¯å¤©18:30æ‰§è¡Œï¼‰
    
    åŠŸèƒ½ï¼š
    1. ä»Šæ—¥ä»»åŠ¡å®Œæˆç»Ÿè®¡
    2. ä»Šæ—¥é‚®ä»¶å¤„ç†æƒ…å†µ
    3. æ˜æ—¥å¾…åŠæé†’
    4. AIå›¢é˜Ÿå·¥ä½œæˆæœ
    """
    try:
        from app.api.wechat_assistant import send_text_message
        from app.models.database import AsyncSessionLocal
        from sqlalchemy import text
        import pytz
        
        logger.info("[Mariaæ™šæŠ¥] ç”Ÿæˆæ™šé—´å·¥ä½œæ€»ç»“...")
        
        CHINA_TZ = pytz.timezone('Asia/Shanghai')
        now = datetime.now(CHINA_TZ)
        
        summary_parts = [f"éƒ‘æ€»ï¼Œä»Šæ—¥ï¼ˆ{now.month}æœˆ{now.day}æ—¥ï¼‰å·¥ä½œæ€»ç»“ï¼š\n"]
        
        agent_names = {
            "coordinator": "å°è°ƒ", "video_creator": "å°å½±",
            "copywriter": "å°æ–‡", "sales": "å°é”€",
            "follow": "å°è·Ÿ", "analyst": "å°æ",
            "lead_hunter": "å°çŒ", "analyst2": "å°æ2",
            "eu_customs_monitor": "å°æ¬§é—´è°",
        }
        
        async with AsyncSessionLocal() as db:
            # ===== 1. ä»Šæ—¥AIä»»åŠ¡ç»Ÿè®¡ =====
            result = await db.execute(
                text("""
                    SELECT 
                        COUNT(*) FILTER (WHERE status = 'completed') as completed,
                        COUNT(*) FILTER (WHERE status = 'failed') as failed,
                        COUNT(*) FILTER (WHERE status = 'pending') as pending
                    FROM ai_tasks 
                    WHERE DATE(created_at) = CURRENT_DATE
                """)
            )
            row = result.fetchone()
            completed, failed, pending = row[0] or 0, row[1] or 0, row[2] or 0
            
            summary_parts.append(f"ğŸ“Š AIå›¢é˜Ÿä»»åŠ¡ï¼šå®Œæˆ {completed} | å¤±è´¥ {failed} | å¾…å¤„ç† {pending}")
            
            # ===== 2. å„å‘˜å·¥å·¥ä½œé‡ =====
            result = await db.execute(
                text("""
                    SELECT agent_type, COUNT(*) as cnt
                    FROM ai_tasks 
                    WHERE DATE(created_at) = CURRENT_DATE
                    AND status = 'completed'
                    GROUP BY agent_type
                    ORDER BY cnt DESC
                    LIMIT 5
                """)
            )
            top_workers = result.fetchall()
            
            if top_workers:
                summary_parts.append("\nä»Šæ—¥æœ€æ´»è·ƒå‘˜å·¥ï¼š")
                for row in top_workers:
                    name = agent_names.get(row[0], row[0])
                    summary_parts.append(f"  â€¢ {name}: {row[1]}ä¸ªä»»åŠ¡")
            
            # ===== 3. ä»Šæ—¥æ—¥ç¨‹å®Œæˆæƒ…å†µ =====
            result = await db.execute(
                text("""
                    SELECT 
                        COUNT(*) FILTER (WHERE is_completed = TRUE) as done,
                        COUNT(*) as total
                    FROM assistant_schedules
                    WHERE DATE(start_time) = CURRENT_DATE
                """)
            )
            row = result.fetchone()
            done_schedules, total_schedules = row[0] or 0, row[1] or 0
            
            if total_schedules > 0:
                summary_parts.append(f"\nğŸ“… ä»Šæ—¥æ—¥ç¨‹ï¼š{done_schedules}/{total_schedules} å®Œæˆ")
            
            # ===== 4. æ˜æ—¥å®‰æ’é¢„è§ˆ =====
            tomorrow = (now + timedelta(days=1)).date()
            result = await db.execute(
                text("""
                    SELECT title, start_time
                    FROM assistant_schedules
                    WHERE DATE(start_time) = :tomorrow
                    AND is_completed = FALSE
                    ORDER BY start_time ASC
                    LIMIT 5
                """),
                {"tomorrow": tomorrow}
            )
            tomorrow_schedules = result.fetchall()
            
            if tomorrow_schedules:
                weekday_names = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"]
                weekday = weekday_names[tomorrow.weekday()]
                summary_parts.append(f"\nğŸ“Œ æ˜æ—¥å®‰æ’ï¼ˆ{tomorrow.month}æœˆ{tomorrow.day}æ—¥ {weekday}ï¼‰ï¼š")
                for s in tomorrow_schedules:
                    if s[1]:
                        if s[1].tzinfo is None:
                            st = pytz.UTC.localize(s[1])
                        else:
                            st = s[1]
                        time_str = st.astimezone(CHINA_TZ).strftime("%H:%M")
                    else:
                        time_str = "å…¨å¤©"
                    summary_parts.append(f"  â€¢ {time_str} {s[0]}")
        
        # ===== 5. é‚®ä»¶æƒ…å†µ =====
        try:
            from app.services.multi_email_service import multi_email_service
            email_summary = await multi_email_service.get_unread_summary()
            unread = email_summary.get("total_unread", 0)
            if unread > 0:
                summary_parts.append(f"\nğŸ“¬ æœªè¯»é‚®ä»¶ï¼š{unread}å°")
        except Exception:
            pass
        
        summary_parts.append("\nè¾›è‹¦äº†ï¼æœ‰äº‹éšæ—¶å«æˆ‘ã€‚")
        
        # å‘é€æ™šæŠ¥
        summary = "\n".join(summary_parts)
        await send_text_message("Frank.Z", summary)
        logger.info("[Mariaæ™šæŠ¥] æ™šé—´å·¥ä½œæ€»ç»“å·²å‘é€")
        
    except Exception as e:
        logger.error(f"[Mariaæ™šæŠ¥] æ™šé—´æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


# ============================================================
# æ··åˆæ–¹æ¡ˆæ–°å¢ï¼šè‡ªåŠ¨åŒ–å·¥ä½œæµä»»åŠ¡
# ============================================================

async def maria_auto_process_new_leads():
    """
    Maria è‡ªåŠ¨å¤„ç†æ–°çº¿ç´¢ï¼ˆæ¯30åˆ†é’Ÿæ‰§è¡Œï¼‰
    
    å·¥ä½œæµï¼š
    1. æŸ¥è¯¢æœ€è¿‘30åˆ†é’Ÿæ–°å‘ç°çš„çº¿ç´¢
    2. è‡ªåŠ¨åˆ†ææ¯æ¡çº¿ç´¢çš„æ„å‘ç­‰çº§
    3. é«˜æ„å‘çº¿ç´¢ï¼šç«‹å³é€šçŸ¥è€æ¿ + ç”Ÿæˆè·Ÿè¿›å»ºè®®
    4. ä¸­æ„å‘çº¿ç´¢ï¼šè®°å½•å¾…è·Ÿè¿›åˆ—è¡¨
    5. ä½æ„å‘çº¿ç´¢ï¼šå½’æ¡£è§‚å¯Ÿ
    """
    import fcntl
    lock_file = "/tmp/maria_auto_leads.lock"
    
    try:
        # æ–‡ä»¶é”é˜²æ­¢é‡å¤æ‰§è¡Œ
        with open(lock_file, "w") as f:
            try:
                fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB)
            except BlockingIOError:
                logger.debug("[Mariaè‡ªåŠ¨åŒ–] çº¿ç´¢å¤„ç†ä»»åŠ¡æ­£åœ¨æ‰§è¡Œï¼Œè·³è¿‡")
                return
            
            from app.models.database import AsyncSessionLocal
            from sqlalchemy import text
            from app.api.wechat_assistant import send_text_message
            
            logger.info("[Mariaè‡ªåŠ¨åŒ–] å¼€å§‹è‡ªåŠ¨å¤„ç†æ–°çº¿ç´¢...")
            
            async with AsyncSessionLocal() as db:
                # 1. æŸ¥è¯¢æœ€è¿‘30åˆ†é’Ÿä¸”æœªå¤„ç†çš„æ–°çº¿ç´¢
                result = await db.execute(
                    text("""
                        SELECT id, source, source_url, content, ai_summary, intent_level,
                               ai_confidence, language, created_at
                        FROM leads
                        WHERE status = 'new'
                        AND created_at > NOW() - INTERVAL '30 minutes'
                        AND intent_level IS NOT NULL
                        ORDER BY ai_confidence DESC
                        LIMIT 10
                    """)
                )
                new_leads = result.fetchall()
                
                if not new_leads:
                    logger.info("[Mariaè‡ªåŠ¨åŒ–] æœ€è¿‘30åˆ†é’Ÿæ²¡æœ‰æ–°çº¿ç´¢")
                    fcntl.flock(f, fcntl.LOCK_UN)
                    return
                
                logger.info(f"[Mariaè‡ªåŠ¨åŒ–] å‘ç° {len(new_leads)} æ¡æ–°çº¿ç´¢ï¼Œå¼€å§‹å¤„ç†")
                
                high_intent_leads = []
                medium_intent_leads = []
                
                for lead in new_leads:
                    lead_id = lead[0]
                    source = lead[1]
                    source_url = lead[2]
                    content = lead[3]
                    ai_summary = lead[4]
                    intent_level = lead[5]
                    confidence = lead[6]
                    language = lead[7]
                    created_at = lead[8]
                    
                    # æ ¹æ®æ„å‘ç­‰çº§åˆ†ç±»
                    if intent_level == 'high':
                        high_intent_leads.append({
                            "id": lead_id,
                            "source": source,
                            "summary": ai_summary or "æš‚æ— æ‘˜è¦",
                            "confidence": f"{int(confidence * 100)}%" if confidence else "æœªçŸ¥",
                            "url": source_url,
                            "language": language or "zh"
                        })
                        
                        # æ›´æ–°çŠ¶æ€ä¸ºå¾…è·Ÿè¿›
                        await db.execute(
                            text("UPDATE leads SET status = 'following' WHERE id = :id"),
                            {"id": lead_id}
                        )
                        
                    elif intent_level == 'medium':
                        medium_intent_leads.append({
                            "id": lead_id,
                            "source": source,
                            "summary": ai_summary or "æš‚æ— æ‘˜è¦"
                        })
                        
                        # æ›´æ–°çŠ¶æ€ä¸ºå·²åˆ†æ
                        await db.execute(
                            text("UPDATE leads SET status = 'analyzed' WHERE id = :id"),
                            {"id": lead_id}
                        )
                    else:
                        # ä½æ„å‘å½’æ¡£
                        await db.execute(
                            text("UPDATE leads SET status = 'archived' WHERE id = :id"),
                            {"id": lead_id}
                        )
                
                await db.commit()
                
                # 2. é«˜æ„å‘çº¿ç´¢ç«‹å³é€šçŸ¥è€æ¿
                if high_intent_leads:
                    message = f"ğŸ¯ Mariaå‘ç° {len(high_intent_leads)} æ¡é«˜æ„å‘çº¿ç´¢ï¼\n\n"
                    
                    for i, lead in enumerate(high_intent_leads[:5], 1):
                        message += f"{i}. ã€{lead['source']}ã€‘\n"
                        message += f"   ğŸ“ {lead['summary'][:50]}...\n"
                        message += f"   ğŸ¯ æ„å‘åº¦: {lead['confidence']}\n"
                        if lead.get('url'):
                            message += f"   ğŸ”— {lead['url'][:50]}...\n"
                        message += "\n"
                    
                    if len(high_intent_leads) > 5:
                        message += f"è¿˜æœ‰ {len(high_intent_leads) - 5} æ¡é«˜æ„å‘çº¿ç´¢...\n"
                    
                    message += "éœ€è¦æˆ‘å¸®æ‚¨ç”Ÿæˆè·Ÿè¿›è¯æœ¯å—ï¼Ÿ"
                    
                    await send_text_message("Frank.Z", message)
                    logger.info(f"[Mariaè‡ªåŠ¨åŒ–] å·²é€šçŸ¥è€æ¿ {len(high_intent_leads)} æ¡é«˜æ„å‘çº¿ç´¢")
                
                # 3. ä¸­æ„å‘çº¿ç´¢æ±‡æ€»ï¼ˆæ¯æ—¥æ±‡æŠ¥ï¼Œä¸å³æ—¶é€šçŸ¥ï¼‰
                if medium_intent_leads:
                    # è®°å½•åˆ°æ—¥å¿—ï¼Œæ™šæŠ¥æ—¶æ±‡æ€»
                    logger.info(f"[Mariaè‡ªåŠ¨åŒ–] å‘ç° {len(medium_intent_leads)} æ¡ä¸­æ„å‘çº¿ç´¢ï¼Œå·²è®°å½•")
            
            fcntl.flock(f, fcntl.LOCK_UN)
            logger.info("[Mariaè‡ªåŠ¨åŒ–] æ–°çº¿ç´¢å¤„ç†å®Œæˆ")
            
    except Exception as e:
        logger.error(f"[Mariaè‡ªåŠ¨åŒ–] å¤„ç†æ–°çº¿ç´¢å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


async def maria_auto_followup_reminder():
    """
    Maria è‡ªåŠ¨è·Ÿè¿›æé†’ï¼ˆæ¯å¤©10:00å’Œ15:00æ‰§è¡Œï¼‰
    
    åŠŸèƒ½ï¼š
    1. æŸ¥è¯¢éœ€è¦ä»Šæ—¥è·Ÿè¿›çš„å®¢æˆ·
    2. ç”Ÿæˆè·Ÿè¿›è¯æœ¯å»ºè®®
    3. å‘é€æé†’ç»™è€æ¿
    """
    try:
        from app.models.database import AsyncSessionLocal
        from sqlalchemy import text
        from app.api.wechat_assistant import send_text_message
        import pytz
        
        logger.info("[Mariaè‡ªåŠ¨åŒ–] æ£€æŸ¥ä»Šæ—¥å¾…è·Ÿè¿›å®¢æˆ·...")
        
        CHINA_TZ = pytz.timezone('Asia/Shanghai')
        now = datetime.now(CHINA_TZ)
        
        async with AsyncSessionLocal() as db:
            # æŸ¥è¯¢ä»Šæ—¥éœ€è¦è·Ÿè¿›çš„å®¢æˆ·
            result = await db.execute(
                text("""
                    SELECT c.id, c.name, c.company, c.email, c.intent_level,
                           c.last_contact_at, c.next_contact_at, c.notes
                    FROM customers c
                    WHERE DATE(c.next_contact_at) = CURRENT_DATE
                    AND c.status = 'active'
                    ORDER BY c.intent_level DESC, c.next_contact_at ASC
                    LIMIT 10
                """)
            )
            customers = result.fetchall()
            
            if not customers:
                logger.info("[Mariaè‡ªåŠ¨åŒ–] ä»Šæ—¥æ²¡æœ‰éœ€è¦è·Ÿè¿›çš„å®¢æˆ·")
                return
            
            # æŒ‰æ„å‘åˆ†ç»„
            high_intent = [c for c in customers if c[4] == 'high']
            other_intent = [c for c in customers if c[4] != 'high']
            
            message = f"ğŸ“‹ éƒ‘æ€»ï¼Œä»Šæ—¥æœ‰ {len(customers)} ä½å®¢æˆ·éœ€è¦è·Ÿè¿›ï¼š\n\n"
            
            if high_intent:
                message += "ğŸ”¥ é«˜æ„å‘å®¢æˆ·ï¼ˆä¼˜å…ˆï¼‰ï¼š\n"
                for c in high_intent[:3]:
                    name = c[1] or "æœªçŸ¥"
                    company = c[2] or ""
                    email = c[3] or ""
                    last_contact = c[5]
                    notes = c[7] or ""
                    
                    message += f"â€¢ {name}"
                    if company:
                        message += f" ({company})"
                    message += "\n"
                    
                    if last_contact:
                        days_ago = (now.date() - last_contact.date()).days
                        message += f"  ä¸Šæ¬¡è”ç³»: {days_ago}å¤©å‰\n"
                    
                    if notes:
                        message += f"  å¤‡æ³¨: {notes[:30]}...\n"
                    
                    message += "\n"
            
            if other_intent:
                message += f"\nğŸ“Œ å…¶ä»–å®¢æˆ·ï¼š{len(other_intent)} ä½\n"
                for c in other_intent[:3]:
                    name = c[1] or "æœªçŸ¥"
                    company = c[2] or ""
                    message += f"â€¢ {name}"
                    if company:
                        message += f" ({company})"
                    message += "\n"
            
            message += "\néœ€è¦æˆ‘å¸®æ‚¨ç”Ÿæˆè·Ÿè¿›é‚®ä»¶æˆ–è¯æœ¯å—ï¼Ÿ"
            
            await send_text_message("Frank.Z", message)
            logger.info(f"[Mariaè‡ªåŠ¨åŒ–] å·²å‘é€è·Ÿè¿›æé†’ï¼Œ{len(customers)} ä½å®¢æˆ·")
            
    except Exception as e:
        logger.error(f"[Mariaè‡ªåŠ¨åŒ–] è·Ÿè¿›æé†’å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


async def maria_lead_hunt_scheduler():
    """
    Maria è‡ªåŠ¨çº¿ç´¢ç‹©çŒè°ƒåº¦ï¼ˆæ¯3å°æ—¶æ‰§è¡Œï¼‰
    
    åŠŸèƒ½ï¼š
    1. æ ¹æ®æ—¶é—´æ®µæ™ºèƒ½è°ƒåº¦çº¿ç´¢æœç´¢
    2. å·¥ä½œæ—¶é—´(9-21ç‚¹)æ‰§è¡Œæœç´¢
    3. è‡ªåŠ¨è°ƒç”¨å°çŒæœç´¢çº¿ç´¢
    4. æœç´¢å®Œæˆåè§¦å‘è‡ªåŠ¨å¤„ç†æµç¨‹
    """
    import fcntl
    lock_file = "/tmp/maria_lead_hunt.lock"
    
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨å·¥ä½œæ—¶é—´
        import pytz
        CHINA_TZ = pytz.timezone('Asia/Shanghai')
        now = datetime.now(CHINA_TZ)
        
        if not (9 <= now.hour < 21):
            logger.info(f"[Mariaè‡ªåŠ¨åŒ–] å½“å‰ {now.hour}:00 ä¸åœ¨å·¥ä½œæ—¶é—´(9-21ç‚¹)ï¼Œè·³è¿‡çº¿ç´¢æœç´¢")
            return
        
        # æ–‡ä»¶é”é˜²æ­¢é‡å¤æ‰§è¡Œ
        with open(lock_file, "w") as f:
            try:
                fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB)
            except BlockingIOError:
                logger.debug("[Mariaè‡ªåŠ¨åŒ–] çº¿ç´¢ç‹©çŒä»»åŠ¡æ­£åœ¨æ‰§è¡Œï¼Œè·³è¿‡")
                return
            
            logger.info("[Mariaè‡ªåŠ¨åŒ–] å¯åŠ¨è‡ªåŠ¨çº¿ç´¢ç‹©çŒ...")
            
            # ç›´æ¥è°ƒç”¨å°çŒçš„æ™ºèƒ½ç‹©çŒ
            from app.agents.lead_hunter import lead_hunter_agent
            
            result = await lead_hunter_agent.process({
                "action": "smart_hunt",
                "max_keywords": 3,  # æ¯æ¬¡æœç´¢3ä¸ªå…³é”®è¯
                "max_results": 15   # æ¯æ¬¡æœ€å¤šåˆ†æ15æ¡
            })
            
            leads_found = result.get("total_leads", 0)
            high_intent = result.get("high_intent_leads", 0)
            
            logger.info(f"[Mariaè‡ªåŠ¨åŒ–] çº¿ç´¢ç‹©çŒå®Œæˆ: å‘ç° {leads_found} æ¡çº¿ç´¢ï¼Œé«˜æ„å‘ {high_intent} æ¡")
            
            # å¦‚æœå‘ç°çº¿ç´¢ï¼Œè§¦å‘è‡ªåŠ¨å¤„ç†
            if leads_found > 0:
                await maria_auto_process_new_leads()
            
            fcntl.flock(f, fcntl.LOCK_UN)
            
    except Exception as e:
        logger.error(f"[Mariaè‡ªåŠ¨åŒ–] çº¿ç´¢ç‹©çŒè°ƒåº¦å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


# ============================================================
# å°çŸ¥ - æ™ºèƒ½çŸ¥è¯†é‡‡é›†ä¸è¿­ä»£ä»»åŠ¡
# ============================================================

async def xiaozhi_auto_knowledge_collection():
    """
    å°çŸ¥ - è‡ªåŠ¨çŸ¥è¯†é‡‡é›†ä»»åŠ¡ï¼ˆæ¯2å°æ—¶æ‰§è¡Œï¼‰
    
    åŠŸèƒ½ï¼š
    1. ä»ç¾¤æ¶ˆæ¯ä¸­æå–æœ‰ä»·å€¼çš„çŸ¥è¯†
    2. ä»å®¢æˆ·å¯¹è¯ä¸­æå–FAQå’Œç—›ç‚¹
    3. ä»æµ·å…³é¢„è­¦ä¸­æå–æ”¿ç­–çŸ¥è¯†
    4. å»é‡ã€åˆ†ç±»ã€å…¥åº“
    """
    import fcntl
    lock_file = "/tmp/xiaozhi_knowledge.lock"
    
    try:
        # æ–‡ä»¶é”é˜²æ­¢é‡å¤æ‰§è¡Œ
        with open(lock_file, "w") as f:
            try:
                fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB)
            except BlockingIOError:
                logger.debug("[å°çŸ¥] çŸ¥è¯†é‡‡é›†ä»»åŠ¡æ­£åœ¨æ‰§è¡Œï¼Œè·³è¿‡")
                return
            
            logger.info("[å°çŸ¥] ğŸ§  å¯åŠ¨è‡ªåŠ¨çŸ¥è¯†é‡‡é›†...")
            
            from app.models.database import async_session_maker
            from sqlalchemy import text
            from app.services.knowledge_base import knowledge_base
            import json
            
            stats = {
                "collected": 0,
                "added": 0,
                "merged": 0,
                "rejected": 0
            }
            
            async with async_session_maker() as db:
                # 1. ä»ç¾¤æ¶ˆæ¯ä¸­æå–çŸ¥è¯†ï¼ˆæœ€è¿‘2å°æ—¶çš„æœ‰ä»·å€¼æ¶ˆæ¯ï¼‰
                try:
                    result = await db.execute(
                        text("""
                            SELECT id, content, analysis_result, group_name
                            FROM wechat_group_messages
                            WHERE created_at > NOW() - INTERVAL '2 hours'
                            AND analysis_result IS NOT NULL
                            AND (analysis_result->>'category' IN ('intel', 'knowledge'))
                            AND NOT EXISTS (
                                SELECT 1 FROM knowledge_base kb 
                                WHERE kb.source_id = CAST(wechat_group_messages.id AS TEXT)
                            )
                            LIMIT 20
                        """)
                    )
                    group_messages = result.fetchall()
                    
                    for msg in group_messages:
                        stats["collected"] += 1
                        msg_id, content, analysis, group_name = msg
                        
                        if analysis:
                            analysis_data = analysis if isinstance(analysis, dict) else json.loads(analysis)
                            category = analysis_data.get("category", "intel")
                            summary = analysis_data.get("summary", content[:200])
                            
                            # æ˜ å°„åˆ°çŸ¥è¯†ç±»å‹
                            type_mapping = {
                                "intel": "market_intel",
                                "knowledge": "clearance_exp"
                            }
                            knowledge_type = type_mapping.get(category, "faq")
                            
                            # æå–æ ‡ç­¾
                            tags = []
                            if "è¿ä»·" in content or "ä»·æ ¼" in content:
                                tags.append("è¿ä»·")
                                knowledge_type = "price_ref"
                            if "æ¸…å…³" in content or "æµ·å…³" in content:
                                tags.append("æ¸…å…³")
                            if "æ”¿ç­–" in content or "æ³•è§„" in content:
                                tags.append("æ”¿ç­–")
                                knowledge_type = "policy"
                            
                            tags.append(group_name[:20] if group_name else "å¾®ä¿¡ç¾¤")
                            
                            # æ·»åŠ åˆ°çŸ¥è¯†åº“
                            knowledge_id = await knowledge_base.add_knowledge(
                                content=summary if len(summary) > 50 else content[:500],
                                knowledge_type=knowledge_type,
                                source="wechat_group",
                                source_id=str(msg_id),
                                tags=tags,
                                is_verified=False
                            )
                            
                            if knowledge_id:
                                stats["added"] += 1
                                logger.debug(f"[å°çŸ¥] ä»ç¾¤æ¶ˆæ¯æå–çŸ¥è¯†: {summary[:50]}...")
                            
                except Exception as e:
                    logger.warning(f"[å°çŸ¥] ç¾¤æ¶ˆæ¯çŸ¥è¯†æå–å¤±è´¥: {e}")
                
                # 2. ä»å®¢æˆ·å¯¹è¯ä¸­æå–FAQï¼ˆè¯†åˆ«é«˜é¢‘é—®é¢˜ï¼‰
                try:
                    result = await db.execute(
                        text("""
                            SELECT content, COUNT(*) as freq
                            FROM (
                                SELECT LOWER(SUBSTRING(content FROM 1 FOR 50)) as content
                                FROM customer_conversations
                                WHERE created_at > NOW() - INTERVAL '24 hours'
                                AND role = 'user'
                                AND content LIKE '%ï¼Ÿ%' OR content LIKE '%å—%' OR content LIKE '%æ€ä¹ˆ%'
                            ) sub
                            GROUP BY content
                            HAVING COUNT(*) >= 2
                            ORDER BY freq DESC
                            LIMIT 5
                        """)
                    )
                    frequent_questions = result.fetchall()
                    
                    for q in frequent_questions:
                        question, freq = q
                        stats["collected"] += 1
                        
                        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç±»ä¼¼FAQ
                        existing = await knowledge_base.search_knowledge(
                            query=question,
                            knowledge_type="faq",
                            limit=1
                        )
                        
                        if not existing:
                            # æ ‡è®°ä¸ºéœ€è¦è¡¥å……FAQï¼ˆæš‚ä¸è‡ªåŠ¨ç”Ÿæˆç­”æ¡ˆï¼‰
                            await knowledge_base.add_knowledge(
                                content=f"[å¾…è¡¥å……ç­”æ¡ˆ] é«˜é¢‘é—®é¢˜({freq}æ¬¡): {question}",
                                knowledge_type="faq",
                                source="customer_chat",
                                tags=["å¾…è¡¥å……", "é«˜é¢‘é—®é¢˜"],
                                is_verified=False
                            )
                            stats["added"] += 1
                            logger.info(f"[å°çŸ¥] å‘ç°é«˜é¢‘é—®é¢˜å¾…è¡¥å……: {question}")
                        else:
                            stats["merged"] += 1
                            
                except Exception as e:
                    logger.warning(f"[å°çŸ¥] å®¢æˆ·å¯¹è¯FAQæå–å¤±è´¥: {e}")
                
                # 3. ä»æµ·å…³é¢„è­¦ä¸­æå–æ”¿ç­–çŸ¥è¯†
                try:
                    result = await db.execute(
                        text("""
                            SELECT id, title_cn, summary_cn, news_type, urgency
                            FROM customs_alerts
                            WHERE created_at > NOW() - INTERVAL '24 hours'
                            AND importance_score >= 60
                            AND NOT EXISTS (
                                SELECT 1 FROM knowledge_base kb 
                                WHERE kb.source_id = CAST(customs_alerts.id AS TEXT)
                                AND kb.source = 'customs_alert'
                            )
                            LIMIT 10
                        """)
                    )
                    alerts = result.fetchall()
                    
                    for alert in alerts:
                        stats["collected"] += 1
                        alert_id, title, summary, news_type, urgency = alert
                        
                        tags = ["æµ·å…³", "æ”¿ç­–"]
                        if urgency == "ç´§æ€¥":
                            tags.append("ç´§æ€¥")
                        if news_type:
                            tags.append(news_type)
                        
                        knowledge_id = await knowledge_base.add_knowledge(
                            content=f"{title}\n\n{summary}" if summary else title,
                            knowledge_type="policy",
                            source="customs_alert",
                            source_id=str(alert_id),
                            tags=tags,
                            is_verified=True  # æµ·å…³é¢„è­¦è§†ä¸ºå·²éªŒè¯
                        )
                        
                        if knowledge_id:
                            stats["added"] += 1
                            logger.debug(f"[å°çŸ¥] ä»æµ·å…³é¢„è­¦æå–çŸ¥è¯†: {title[:50]}...")
                            
                except Exception as e:
                    logger.warning(f"[å°çŸ¥] æµ·å…³é¢„è­¦çŸ¥è¯†æå–å¤±è´¥: {e}")
            
            logger.info(f"[å°çŸ¥] âœ… çŸ¥è¯†é‡‡é›†å®Œæˆ: é‡‡é›† {stats['collected']} æ¡ï¼Œæ–°å¢ {stats['added']} æ¡ï¼Œåˆå¹¶ {stats['merged']} æ¡ï¼Œæ‹’ç» {stats['rejected']} æ¡")
            
            fcntl.flock(f, fcntl.LOCK_UN)
            
    except Exception as e:
        logger.error(f"[å°çŸ¥] çŸ¥è¯†é‡‡é›†å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


async def xiaozhi_knowledge_maintenance():
    """
    å°çŸ¥ - çŸ¥è¯†åº“ç»´æŠ¤ä»»åŠ¡ï¼ˆæ¯å¤©å‡Œæ™¨æ‰§è¡Œï¼‰
    
    åŠŸèƒ½ï¼š
    1. æ£€æŸ¥è¿‡æœŸçŸ¥è¯†å¹¶æ ‡è®°
    2. ç»Ÿè®¡çŸ¥è¯†ä½¿ç”¨æƒ…å†µ
    3. ç”ŸæˆçŸ¥è¯†å¥åº·åº¦æŠ¥å‘Š
    4. æ¸…ç†ä½è´¨é‡/æ— ç”¨çŸ¥è¯†
    """
    try:
        logger.info("[å°çŸ¥] ğŸ”§ å¯åŠ¨çŸ¥è¯†åº“ç»´æŠ¤...")
        
        from app.models.database import async_session_maker
        from sqlalchemy import text
        
        async with async_session_maker() as db:
            # 1. æ ‡è®°è¿‡æœŸçŸ¥è¯†ï¼ˆè¿ä»·å‚è€ƒè¶…è¿‡7å¤©ï¼‰
            result = await db.execute(
                text("""
                    UPDATE knowledge_base
                    SET tags = array_append(tags, 'è¿‡æœŸå¾…æ›´æ–°')
                    WHERE knowledge_type = 'price_ref'
                    AND updated_at < NOW() - INTERVAL '7 days'
                    AND NOT ('è¿‡æœŸå¾…æ›´æ–°' = ANY(tags))
                    RETURNING id
                """)
            )
            expired_price = len(result.fetchall())
            
            # 2. æ ‡è®°è¿‡æœŸæ”¿ç­–ï¼ˆè¶…è¿‡30å¤©ï¼‰
            result = await db.execute(
                text("""
                    UPDATE knowledge_base
                    SET tags = array_append(tags, 'å¾…å¤æ ¸')
                    WHERE knowledge_type = 'policy'
                    AND updated_at < NOW() - INTERVAL '30 days'
                    AND NOT ('å¾…å¤æ ¸' = ANY(tags))
                    RETURNING id
                """)
            )
            expired_policy = len(result.fetchall())
            
            # 3. æ¸…ç†ä»æœªä½¿ç”¨ä¸”è¶…è¿‡90å¤©çš„æœªéªŒè¯çŸ¥è¯†
            result = await db.execute(
                text("""
                    DELETE FROM knowledge_base
                    WHERE usage_count = 0
                    AND is_verified = FALSE
                    AND created_at < NOW() - INTERVAL '90 days'
                    RETURNING id
                """)
            )
            cleaned = len(result.fetchall())
            
            # 4. ç»Ÿè®¡çŸ¥è¯†åº“å¥åº·åº¦
            result = await db.execute(
                text("""
                    SELECT 
                        COUNT(*) as total,
                        COUNT(*) FILTER (WHERE is_verified = TRUE) as verified,
                        COUNT(*) FILTER (WHERE usage_count > 0) as used,
                        COUNT(*) FILTER (WHERE 'è¿‡æœŸå¾…æ›´æ–°' = ANY(tags) OR 'å¾…å¤æ ¸' = ANY(tags)) as needs_attention
                    FROM knowledge_base
                """)
            )
            stats = result.fetchone()
            
            await db.commit()
            
            total, verified, used, needs_attention = stats if stats else (0, 0, 0, 0)
            health_score = int((verified / max(total, 1) * 40) + (used / max(total, 1) * 40) + ((1 - needs_attention / max(total, 1)) * 20))
            
            logger.info(f"[å°çŸ¥] âœ… çŸ¥è¯†åº“ç»´æŠ¤å®Œæˆ:")
            logger.info(f"  - è¿ä»·è¿‡æœŸæ ‡è®°: {expired_price} æ¡")
            logger.info(f"  - æ”¿ç­–å¾…å¤æ ¸: {expired_policy} æ¡")
            logger.info(f"  - æ¸…ç†æ— ç”¨çŸ¥è¯†: {cleaned} æ¡")
            logger.info(f"  - çŸ¥è¯†åº“æ€»é‡: {total} æ¡")
            logger.info(f"  - å·²éªŒè¯: {verified} æ¡")
            logger.info(f"  - ä½¿ç”¨è¿‡: {used} æ¡")
            logger.info(f"  - å¥åº·åº¦è¯„åˆ†: {health_score}/100")
            
    except Exception as e:
        logger.error(f"[å°çŸ¥] çŸ¥è¯†åº“ç»´æŠ¤å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


async def xiaozhi_knowledge_gap_check():
    """
    å°çŸ¥ - çŸ¥è¯†ç¼ºå£æ£€æŸ¥ï¼ˆæ¯å‘¨æ‰§è¡Œï¼‰
    
    åŠŸèƒ½ï¼š
    1. åˆ†æå®¢æˆ·é«˜é¢‘é—®é¢˜ vs çŸ¥è¯†åº“è¦†ç›–
    2. è¯†åˆ«çŸ¥è¯†ç¼ºå£
    3. ç”Ÿæˆè¡¥å……å»ºè®®
    """
    try:
        logger.info("[å°çŸ¥] ğŸ” å¯åŠ¨çŸ¥è¯†ç¼ºå£åˆ†æ...")
        
        from app.models.database import async_session_maker
        from sqlalchemy import text
        
        gaps = []
        
        async with async_session_maker() as db:
            # 1. åˆ†ææœ€è¿‘ä¸€å‘¨çš„å®¢æˆ·é«˜é¢‘é—®é¢˜
            result = await db.execute(
                text("""
                    SELECT 
                        CASE 
                            WHEN content ILIKE '%æ—¶æ•ˆ%' OR content ILIKE '%å¤šä¹…%' THEN 'æ—¶æ•ˆæŸ¥è¯¢'
                            WHEN content ILIKE '%ä»·æ ¼%' OR content ILIKE '%å¤šå°‘é’±%' OR content ILIKE '%æŠ¥ä»·%' THEN 'ä»·æ ¼å’¨è¯¢'
                            WHEN content ILIKE '%æ¸…å…³%' OR content ILIKE '%æµ·å…³%' THEN 'æ¸…å…³é—®é¢˜'
                            WHEN content ILIKE '%VAT%' OR content ILIKE '%ç¨%' THEN 'VATç¨åŠ¡'
                            WHEN content ILIKE '%å¸¦ç”µ%' OR content ILIKE '%ç”µæ± %' THEN 'å¸¦ç”µäº§å“'
                            WHEN content ILIKE '%é€€è´§%' OR content ILIKE '%é€€å›%' THEN 'é€€è´§å¤„ç†'
                            ELSE 'å…¶ä»–'
                        END as topic,
                        COUNT(*) as freq
                    FROM customer_conversations
                    WHERE created_at > NOW() - INTERVAL '7 days'
                    AND role = 'user'
                    GROUP BY topic
                    HAVING COUNT(*) >= 3
                    ORDER BY freq DESC
                """)
            )
            hot_topics = result.fetchall()
            
            # 2. æ£€æŸ¥æ¯ä¸ªçƒ­é—¨è¯é¢˜çš„çŸ¥è¯†è¦†ç›–
            for topic, freq in hot_topics:
                if topic == 'å…¶ä»–':
                    continue
                    
                # æœç´¢ç›¸å…³çŸ¥è¯†
                result = await db.execute(
                    text("""
                        SELECT COUNT(*) 
                        FROM knowledge_base
                        WHERE content ILIKE :pattern
                        AND is_verified = TRUE
                    """),
                    {"pattern": f"%{topic.replace('æŸ¥è¯¢', '').replace('å’¨è¯¢', '').replace('é—®é¢˜', '')}%"}
                )
                coverage = result.scalar() or 0
                
                if coverage < 3:  # ç›¸å…³çŸ¥è¯†å°‘äº3æ¡è§†ä¸ºç¼ºå£
                    gaps.append({
                        "topic": topic,
                        "query_frequency": freq,
                        "knowledge_coverage": coverage,
                        "severity": "é«˜" if coverage == 0 else "ä¸­"
                    })
            
            if gaps:
                logger.warning(f"[å°çŸ¥] âš ï¸ å‘ç° {len(gaps)} ä¸ªçŸ¥è¯†ç¼ºå£:")
                for gap in gaps:
                    logger.warning(f"  - {gap['topic']}: å’¨è¯¢{gap['query_frequency']}æ¬¡ï¼ŒçŸ¥è¯†è¦†ç›–{gap['knowledge_coverage']}æ¡")
                
                # å¯ä»¥åœ¨è¿™é‡Œå‘é€é€šçŸ¥ç»™è€æ¿
                # TODO: é›†æˆé€šçŸ¥åŠŸèƒ½
            else:
                logger.info("[å°çŸ¥] âœ… çŸ¥è¯†è¦†ç›–è‰¯å¥½ï¼Œæœªå‘ç°æ˜æ˜¾ç¼ºå£")
                
    except Exception as e:
        logger.error(f"[å°çŸ¥] çŸ¥è¯†ç¼ºå£åˆ†æå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
