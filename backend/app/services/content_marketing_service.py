"""
å†…å®¹è¥é”€æœåŠ¡
è´Ÿè´£è‡ªåŠ¨ç”Ÿæˆå¤šå¹³å°è¥é”€å†…å®¹
"""
from typing import Dict, Any, List, Optional
from datetime import datetime, date, timedelta
from loguru import logger
from sqlalchemy import text
import json
import uuid

from app.models.database import async_session_maker
from app.agents.copywriter import copywriter_agent


class ContentMarketingService:
    """å†…å®¹è¥é”€æœåŠ¡"""
    
    # å†…å®¹ç±»å‹é…ç½®ï¼ˆå¯¹åº”æ˜ŸæœŸå‡ ï¼‰
    CONTENT_SCHEDULE = {
        1: {"type": "knowledge", "name": "ç‰©æµçŸ¥è¯†", "emoji": "ğŸ“š"},
        2: {"type": "pricing", "name": "è¿ä»·æ’­æŠ¥", "emoji": "ğŸ’°"},
        3: {"type": "case", "name": "æˆåŠŸæ¡ˆä¾‹", "emoji": "âœ…"},
        4: {"type": "policy", "name": "æ”¿ç­–è§£è¯»", "emoji": "ğŸ“¢"},
        5: {"type": "faq", "name": "çƒ­é—¨é—®ç­”", "emoji": "â“"},
        6: {"type": "story", "name": "å…¬å¸æ•…äº‹", "emoji": "ğŸ¢"},
        7: {"type": "weekly", "name": "å‘¨æŠ¥æ€»ç»“", "emoji": "ğŸ“Š"},
    }
    
    # æ”¯æŒçš„å¹³å°
    PLATFORMS = ["douyin", "xiaohongshu", "wechat_article", "wechat_moments"]
    
    # å¹³å°åç§°æ˜ å°„
    PLATFORM_NAMES = {
        "douyin": "æŠ–éŸ³",
        "xiaohongshu": "å°çº¢ä¹¦",
        "wechat_article": "å…¬ä¼—å·æ–‡ç« ",
        "wechat_moments": "æœ‹å‹åœˆ",
        "video_account": "è§†é¢‘å·"
    }
    
    async def generate_daily_content(self, target_date: date = None) -> Dict[str, Any]:
        """
        ç”ŸæˆæŒ‡å®šæ—¥æœŸçš„å†…å®¹
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºæ˜å¤©
        
        Returns:
            ç”Ÿæˆç»“æœ
        """
        if target_date is None:
            target_date = date.today() + timedelta(days=1)
        
        day_of_week = target_date.isoweekday()  # 1-7 å¯¹åº”å‘¨ä¸€åˆ°å‘¨æ—¥
        content_config = self.CONTENT_SCHEDULE.get(day_of_week, self.CONTENT_SCHEDULE[1])
        
        logger.info(f"ğŸ“ å¼€å§‹ç”Ÿæˆ {target_date} çš„å†…å®¹: {content_config['name']}")
        
        try:
            async with async_session_maker() as db:
                # 1. æ£€æŸ¥æ˜¯å¦å·²æœ‰è¯¥æ—¥æœŸçš„å†…å®¹è®¡åˆ’
                existing = await db.execute(
                    text("""
                        SELECT id, status FROM content_calendar 
                        WHERE content_date = :date AND content_type = :type
                    """),
                    {"date": target_date, "type": content_config["type"]}
                )
                existing_row = existing.fetchone()
                
                # å¦‚æœå·²å­˜åœ¨ä¸”çŠ¶æ€æ˜¯ generating æˆ– generatedï¼Œåˆ™è·³è¿‡
                if existing_row and existing_row[1] in ('generating', 'generated'):
                    logger.info(f"ğŸ“ {target_date} çš„å†…å®¹å·²å­˜åœ¨(çŠ¶æ€: {existing_row[1]})ï¼Œè·³è¿‡")
                    return {"status": "skipped", "message": "å†…å®¹å·²å­˜åœ¨æˆ–æ­£åœ¨ç”Ÿæˆ"}
                
                # 2. è·å–æ•°æ®æº
                data_source = await self._get_data_source(content_config["type"], db)
                
                # 3. åˆ›å»ºæˆ–æ›´æ–°å†…å®¹æ—¥å†è®°å½•
                if existing_row:
                    calendar_id = existing_row[0]
                    await db.execute(
                        text("""
                            UPDATE content_calendar 
                            SET status = 'generating', data_source = :data_source
                            WHERE id = :id
                        """),
                        {"id": calendar_id, "data_source": json.dumps(data_source, ensure_ascii=False)}
                    )
                else:
                    calendar_id = str(uuid.uuid4())
                    await db.execute(
                        text("""
                            INSERT INTO content_calendar 
                            (id, content_date, day_of_week, content_type, status, data_source)
                            VALUES (:id, :date, :dow, :type, 'generating', :data_source)
                        """),
                        {
                            "id": calendar_id,
                            "date": target_date,
                            "dow": day_of_week,
                            "type": content_config["type"],
                            "data_source": json.dumps(data_source, ensure_ascii=False)
                        }
                    )
                
                await db.commit()
                
                # 4. ä¸ºæ¯ä¸ªå¹³å°ç”Ÿæˆå†…å®¹
                generated_items = []
                for platform in self.PLATFORMS:
                    try:
                        content_item = await self._generate_content_for_platform(
                            content_type=content_config["type"],
                            platform=platform,
                            data_source=data_source,
                            db=db
                        )
                        
                        # ä¿å­˜å†…å®¹
                        item_id = str(uuid.uuid4())
                        await db.execute(
                            text("""
                                INSERT INTO content_items 
                                (id, calendar_id, platform, title, content, hashtags, 
                                 call_to_action, contact_info, video_script, status)
                                VALUES (:id, :calendar_id, :platform, :title, :content, :hashtags,
                                        :cta, :contact, :video_script, 'draft')
                            """),
                            {
                                "id": item_id,
                                "calendar_id": calendar_id,
                                "platform": platform,
                                "title": content_item.get("title"),
                                "content": content_item.get("content"),
                                "hashtags": content_item.get("hashtags", []),
                                "cta": content_item.get("call_to_action"),
                                "contact": content_item.get("contact_info"),
                                "video_script": content_item.get("video_script")
                            }
                        )
                        
                        generated_items.append({
                            "id": item_id,
                            "platform": platform,
                            "title": content_item.get("title"),
                            "status": "success"
                        })
                        
                        logger.info(f"âœ… ç”Ÿæˆ {self.PLATFORM_NAMES[platform]} å†…å®¹æˆåŠŸ")
                        
                    except Exception as e:
                        logger.error(f"âŒ ç”Ÿæˆ {platform} å†…å®¹å¤±è´¥: {e}")
                        generated_items.append({
                            "platform": platform,
                            "status": "failed",
                            "error": str(e)
                        })
                
                # 5. æ›´æ–°æ—¥å†çŠ¶æ€
                await db.execute(
                    text("""
                        UPDATE content_calendar 
                        SET status = 'generated', generated_at = NOW()
                        WHERE id = :id
                    """),
                    {"id": calendar_id}
                )
                
                await db.commit()
                
                logger.info(f"ğŸ“ {target_date} å†…å®¹ç”Ÿæˆå®Œæˆï¼å…± {len(generated_items)} ä¸ªå¹³å°")
                
                return {
                    "status": "success",
                    "date": str(target_date),
                    "content_type": content_config["type"],
                    "content_name": content_config["name"],
                    "calendar_id": calendar_id,
                    "items": generated_items
                }
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¯æ—¥å†…å®¹å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {"status": "failed", "error": str(e)}
    
    async def _get_data_source(self, content_type: str, db) -> Dict[str, Any]:
        """
        æ ¹æ®å†…å®¹ç±»å‹è·å–æ•°æ®æº
        """
        data = {
            "type": content_type,
            "generated_at": datetime.now().isoformat()
        }
        
        # è·å–å…¬å¸é…ç½®ï¼ˆåŒ…å«èšç„¦å¸‚åœºç­‰æ–°å­—æ®µï¼‰
        company_result = await db.execute(
            text("""
                SELECT company_name, company_intro, advantages, service_routes,
                       focus_markets, business_scope, brand_slogan, content_tone,
                       content_focus_keywords, forbidden_content, social_media
                FROM company_config LIMIT 1
            """)
        )
        company = company_result.fetchone()
        
        if company:
            data["company"] = {
                "name": company[0],  # company_name
                "intro": company[1],  # company_intro
                "advantages": company[2] or [],  # advantages
                "service_routes": company[3] or [],  # service_routes
                "focus_markets": company[4] or [],  # èšç„¦å¸‚åœº
                "business_scope": company[5],  # ä¸šåŠ¡èŒƒå›´æè¿°
                "brand_slogan": company[6],  # å“ç‰Œå£å·
                "content_tone": company[7] or 'professional',  # å†…å®¹é£æ ¼
                "focus_keywords": company[8] or [],  # å†…å®¹å…³é”®è¯
                "forbidden_content": company[9] or [],  # ç¦æ­¢å†…å®¹
                "social_media": company[10] or {}  # ç¤¾äº¤åª’ä½“è´¦å·
            }
        
        # æ ¹æ®å†…å®¹ç±»å‹è·å–ç‰¹å®šæ•°æ®
        if content_type == "pricing":
            # å°è¯•ä»ERPç¼“å­˜è·å–è¿ä»·æ•°æ®
            pricing_result = await db.execute(
                text("""
                    SELECT data_value FROM erp_data_cache 
                    WHERE data_type = 'pricing' 
                    AND (expires_at IS NULL OR expires_at > NOW())
                    ORDER BY updated_at DESC LIMIT 1
                """)
            )
            pricing = pricing_result.fetchone()
            if pricing:
                data["pricing"] = pricing[0]
            else:
                # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…åº”è¯¥ä»ERPè·å–ï¼‰
                data["pricing"] = await self._get_mock_pricing_data()
        
        elif content_type == "case":
            # è·å–æˆåŠŸæ¡ˆä¾‹
            data["cases"] = await self._get_mock_case_data()
        
        elif content_type == "policy":
            # è·å–æ”¿ç­–å…¬å‘Š
            data["policy"] = await self._get_mock_policy_data()
        
        elif content_type == "faq":
            # ä»å®¢æˆ·å¯¹è¯ä¸­æå–é«˜é¢‘é—®é¢˜
            data["faq"] = await self._extract_faq_from_conversations(db)
        
        elif content_type == "weekly":
            # è·å–æœ¬å‘¨æ•°æ®æ±‡æ€»
            data["weekly_stats"] = await self._get_weekly_stats(db)
        
        return data
    
    async def _generate_content_for_platform(
        self, 
        content_type: str, 
        platform: str, 
        data_source: Dict[str, Any],
        db
    ) -> Dict[str, Any]:
        """
        ä¸ºæŒ‡å®šå¹³å°ç”Ÿæˆå†…å®¹
        ä¼˜å…ˆä½¿ç”¨AIç”Ÿæˆï¼Œç¡®ä¿å†…å®¹è´¨é‡å’ŒçœŸå®æ€§
        """
        # æ„å»ºæç¤ºè¯
        company_name = data_source.get("company", {}).get("name", "ä¸“ä¸šç‰©æµå…¬å¸")
        
        platform_config = {
            "douyin": {
                "style": "å£è¯­åŒ–ã€æœ‰èŠ‚å¥æ„Ÿã€é€‚åˆçŸ­è§†é¢‘ï¼Œå¼€å¤´è¦æœ‰é’©å­å¸å¼•æ³¨æ„åŠ›",
                "length": "100-200å­—",
                "extra": "éœ€è¦ç”Ÿæˆå®Œæ•´çš„è§†é¢‘è„šæœ¬ï¼ŒåŒ…å«åˆ†é•œç”»é¢æè¿°ã€æ—ç™½ã€å­—å¹•"
            },
            "xiaohongshu": {
                "style": "äº²åˆ‡ã€ç§è‰é£æ ¼ã€å¤šç”¨emojiã€é€‚åˆå›¾æ–‡ï¼Œæœ‰çœŸå®æ„Ÿå’Œä½“éªŒæ„Ÿ",
                "length": "300-500å­—",
                "extra": "æ ‡é¢˜è¦æœ‰æ•°å­—æˆ–ç–‘é—®å¼•å‘å¥½å¥‡ï¼Œæ­£æ–‡åˆ†æ®µæ¸…æ™°ï¼Œçªå‡ºç—›ç‚¹å’Œè§£å†³æ–¹æ¡ˆ"
            },
            "wechat_article": {
                "style": "ä¸“ä¸šã€æ·±åº¦ã€æœ‰å¹²è´§ï¼Œä½“ç°è¡Œä¸šä¸“å®¶å½¢è±¡",
                "length": "800-1500å­—",
                "extra": "éœ€è¦æœ‰å°æ ‡é¢˜ã€åˆ—è¡¨ã€æ¡ˆä¾‹ã€æ€»ç»“ï¼Œå†…å®¹æœ‰æ·±åº¦æœ‰ä»·å€¼"
            },
            "wechat_moments": {
                "style": "ç®€æ´ç²¾ç‚¼ã€æœ‰ä¿¡æ¯é‡ã€é€‚åˆå¿«é€Ÿé˜…è¯»ï¼Œåƒæœ‹å‹åˆ†äº«",
                "length": "50-150å­—",
                "extra": "ä¸éœ€è¦æ ‡é¢˜ï¼Œç›´æ¥æ˜¯æ–‡æ¡ˆï¼Œè¦æœ‰æ¸©åº¦æ„Ÿå’ŒçœŸå®æ„Ÿ"
            }
        }
        
        platform_info = platform_config.get(platform, platform_config["wechat_moments"])
        
        # å§‹ç»ˆä½¿ç”¨AIç”Ÿæˆï¼Œç¡®ä¿å†…å®¹è´¨é‡å’ŒçœŸå®æ€§
        # æ¨¡æ¿å®¹æ˜“å¯¼è‡´å˜é‡æœªæ›¿æ¢æˆ–å†…å®¹åƒç¯‡ä¸€å¾‹
        content = await self._generate_with_ai(
            content_type=content_type,
            platform=platform,
            platform_info=platform_info,
            data_source=data_source,
            company_name=company_name
        )
        
        return content
    
    async def _generate_from_template(
        self, 
        template, 
        data_source: Dict[str, Any],
        platform: str
    ) -> Dict[str, Any]:
        """ä»æ¨¡æ¿ç”Ÿæˆå†…å®¹"""
        title_tpl = template[0] or ""
        content_tpl = template[1] or ""
        hashtags_tpl = template[2] or []
        cta_tpl = template[3] or ""
        
        # æ›¿æ¢å˜é‡
        variables = self._extract_variables(data_source)
        
        title = self._replace_variables(title_tpl, variables)
        content = self._replace_variables(content_tpl, variables)
        cta = self._replace_variables(cta_tpl, variables)
        
        return {
            "title": title if title else None,
            "content": content,
            "hashtags": hashtags_tpl,
            "call_to_action": cta,
            "contact_info": "æ·»åŠ å¾®ä¿¡è·å–è¯¦ç»†æŠ¥ä»·"
        }
    
    async def _generate_with_ai(
        self,
        content_type: str,
        platform: str,
        platform_info: Dict[str, str],
        data_source: Dict[str, Any],
        company_name: str
    ) -> Dict[str, Any]:
        """ä½¿ç”¨AIç”Ÿæˆé«˜è´¨é‡è¥é”€å†…å®¹"""
        
        content_type_names = {
            "knowledge": "ç‰©æµçŸ¥è¯†ç§‘æ™®",
            "pricing": "è¿ä»·æ’­æŠ¥",
            "case": "æˆåŠŸæ¡ˆä¾‹åˆ†äº«",
            "policy": "æ”¿ç­–è§£è¯»",
            "faq": "å¸¸è§é—®é¢˜è§£ç­”",
            "story": "å…¬å¸æ•…äº‹",
            "weekly": "å‘¨æŠ¥æ€»ç»“"
        }
        
        # è·å–å†…å®¹ä¸»é¢˜ï¼ˆåŸºäºå†…å®¹ç±»å‹ç”Ÿæˆå…·ä½“è¯é¢˜ï¼‰
        topic = await self._get_content_topic(content_type, data_source)
        
        # æ„å»ºæ•°æ®æ‘˜è¦
        data_summary = self._build_data_summary(content_type, data_source)
        
        # ä»æ•°æ®æºè·å–å…¬å¸é…ç½®
        company_info = data_source.get("company", {})
        focus_markets = company_info.get("focus_markets", [])
        business_scope = company_info.get("business_scope", "")
        brand_slogan = company_info.get("brand_slogan", "")
        content_tone = company_info.get("content_tone", "professional")
        focus_keywords = company_info.get("focus_keywords", [])
        forbidden_content = company_info.get("forbidden_content", [])
        advantages = company_info.get("advantages", [])
        service_routes = company_info.get("service_routes", [])
        social_media = company_info.get("social_media", {})
        
        # æ„å»ºæœåŠ¡èˆªçº¿æè¿°
        routes_text = ""
        if service_routes:
            routes_list = []
            for route in service_routes[:5]:
                from_loc = route.get("from_location", "ä¸­å›½")
                to_loc = route.get("to_location", "")
                transport = route.get("transport", "")
                time = route.get("time", "")
                if to_loc:
                    routes_list.append(f"{from_loc}â†’{to_loc}({transport}, {time})")
            routes_text = "ï¼›".join(routes_list)
        
        # æ„å»ºæœåŠ¡åŒºåŸŸæè¿°
        focus_region = "æ¬§æ´²å…¨å¢ƒï¼ˆå¾·å›½ã€è·å…°ã€è‹±å›½ã€æ³•å›½ã€æ„å¤§åˆ©ç­‰ï¼‰"
        if focus_markets:
            focus_region = "ã€".join(focus_markets) + "ç­‰åœ°åŒº"
        
        # æ„å»ºé£æ ¼æè¿°
        tone_map = {
            "professional": "ä¸“ä¸šå¯ä¿¡ï¼Œæ•°æ®æ”¯æ’‘ï¼Œä½“ç°è¡Œä¸šç»éªŒ",
            "friendly": "äº²åˆ‡å‹å¥½ï¼Œè´´è¿‘å®¢æˆ·ï¼Œåƒæœ‹å‹èŠå¤©",
            "creative": "åˆ›æ„æ´»æ³¼ï¼Œæœ‰è¶£å¸ç›ï¼Œé€‚åˆä¼ æ’­"
        }
        tone_desc = tone_map.get(content_tone, tone_map["professional"])
        
        # æ„å»ºç¦æ­¢å†…å®¹æé†’
        forbidden_text = ""
        if forbidden_content:
            forbidden_text = f"\nâš ï¸ **ç¦æ­¢æåŠï¼š{', '.join(forbidden_content)}**"
        
        # æ„å»ºç¤¾äº¤åª’ä½“å¼•æµä¿¡æ¯
        social_cta = "ç§ä¿¡/è¯„è®ºå’¨è¯¢"
        if social_media:
            cta_parts = []
            if social_media.get("wechat"):
                cta_parts.append(f"å¾®ä¿¡ã€Œ{social_media['wechat']}ã€")
            if social_media.get("wechat_official"):
                cta_parts.append(f"å…¬ä¼—å·ã€Œ{social_media['wechat_official']}ã€")
            if cta_parts:
                social_cta = "æˆ–".join(cta_parts)
        
        # é’ˆå¯¹ä¸åŒå†…å®¹ç±»å‹çš„ç‰¹æ®ŠæŒ‡å¯¼
        type_specific_guide = self._get_type_specific_guide(content_type, data_source)
        
        # é’ˆå¯¹ä¸åŒå¹³å°çš„è¯¦ç»†è¦æ±‚
        platform_specific_guide = self._get_platform_specific_guide(platform, content_type)
        
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç‰©æµè¡Œä¸šå†…å®¹è¥é”€ä¸“å®¶ï¼Œè¯·ä¸ºã€Œ{company_name}ã€åˆ›ä½œä¸€ç¯‡çœŸå®ã€ä¸“ä¸šã€æœ‰å¸å¼•åŠ›çš„{content_type_names.get(content_type, 'è¥é”€')}å†…å®¹ã€‚

## ä»Šæ—¥å†…å®¹ä¸»é¢˜
{topic}

## å…¬å¸èƒŒæ™¯
- å…¬å¸åç§°ï¼š{company_name}
- å…¬å¸ç®€ä»‹ï¼š{company_info.get('intro', 'ä¸“æ³¨æ¬§æ´²ç‰©æµçš„ä¸“ä¸šæœåŠ¡å•†')}
- æ ¸å¿ƒä¼˜åŠ¿ï¼š{', '.join(advantages) if advantages else '15å¹´æ¬§æ´²ä¸“çº¿ç»éªŒã€å¾·å›½/è·å…°æµ·å¤–ä»“ã€å…¨å¢ƒDDU/DDPæœåŠ¡ã€ä¸€å¯¹ä¸€ä¸“å±å®¢æœ'}
- æœåŠ¡èˆªçº¿ï¼š{routes_text if routes_text else 'ä¸­å›½åˆ°æ¬§æ´²å…¨å¢ƒæµ·è¿/ç©ºè¿/é“è·¯'}
- æœåŠ¡åŒºåŸŸï¼š{focus_region}
{f'- å“ç‰Œå£å·ï¼š{brand_slogan}' if brand_slogan else ''}

## å‘å¸ƒå¹³å°ï¼š{self.PLATFORM_NAMES.get(platform, platform)}

## å¹³å°å†…å®¹è¦æ±‚
- é£æ ¼åŸºè°ƒï¼š{platform_info['style']}
- å†…å®¹é•¿åº¦ï¼š{platform_info['length']}
- ç‰¹æ®Šè¦æ±‚ï¼š{platform_info['extra']}
- æ•´ä½“è°ƒæ€§ï¼š{tone_desc}
{f'- å…³é”®è¯èå…¥ï¼š{", ".join(focus_keywords)}' if focus_keywords else ''}{forbidden_text}

## å†…å®¹ç±»å‹ä¸“é¡¹æŒ‡å¯¼
{type_specific_guide}

## å¹³å°ä¸“é¡¹æŒ‡å¯¼
{platform_specific_guide}

## å¯ç”¨çš„çœŸå®æ•°æ®ï¼ˆè¯·åŸºäºæ­¤åˆ›ä½œï¼‰
{data_summary}

## å¼•æµè½¬åŒ–è¦æ±‚
1. ç»“å°¾å¿…é¡»æœ‰æ¸…æ™°çš„è¡ŒåŠ¨å·å¬ï¼ˆCTAï¼‰
2. å¼ºè°ƒ"å…è´¹å’¨è¯¢"ã€"ä¸“å±æŠ¥ä»·"ã€"ä¸€å¯¹ä¸€æœåŠ¡"ç­‰é’©å­
3. å¼•æµæ–¹å¼ï¼š{social_cta}
4. è¥é€ ç´§è¿«æ„Ÿæˆ–ç¨€ç¼ºæ„Ÿï¼ˆå¦‚"é™æ—¶"ã€"åé¢æœ‰é™"ï¼‰

## å†…å®¹è´¨é‡è¦æ±‚
1. å†…å®¹å¿…é¡»çœŸå®å¯ä¿¡ï¼Œä¸å¤¸å¤§ä¸è™šå‡
2. ç”¨å…·ä½“æ•°æ®å’Œæ¡ˆä¾‹æ”¯æ’‘è§‚ç‚¹
3. è¯­è¨€è‡ªç„¶æµç•…ï¼Œé¿å…æœºæ¢°æ„Ÿ
4. é’ˆå¯¹ç›®æ ‡å®¢æˆ·ï¼ˆå¤–è´¸å•†å®¶ã€è·¨å¢ƒå–å®¶ï¼‰çš„ç—›ç‚¹
5. ä½“ç°ä¸“ä¸šæ€§ä½†ä¸è¦è¿‡äºæ™¦æ¶©

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼æŒ‰JSONæ ¼å¼ï¼‰
{{
    "title": "å¸å¼•äººçš„æ ‡é¢˜ï¼ˆæœ‹å‹åœˆå¯ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰",
    "content": "å®Œæ•´çš„æ­£æ–‡å†…å®¹",
    "hashtags": ["è¯é¢˜1", "è¯é¢˜2", "è¯é¢˜3", "è¯é¢˜4", "è¯é¢˜5"],
    "call_to_action": "æœ‰åŠ›çš„è¡ŒåŠ¨å·å¬è¯­",
    "video_script": "{self._get_video_script_requirement(platform)}"
}}
"""
        
        try:
            response = await copywriter_agent.think([{"role": "user", "content": prompt}])
            
            # è§£æJSON
            json_start = response.find("{")
            json_end = response.rfind("}") + 1
            if json_start != -1 and json_end > json_start:
                result = json.loads(response[json_start:json_end])
                
                # éªŒè¯å†…å®¹ä¸ä¸ºç©º
                if result.get("content") and len(result["content"]) > 20:
                    logger.info(f"âœ… AIæˆåŠŸç”Ÿæˆ {platform} å†…å®¹: {result.get('title', '')[:30]}...")
                return result
                    
        except json.JSONDecodeError as e:
            logger.error(f"AIç”Ÿæˆå†…å®¹JSONè§£æå¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"AIç”Ÿæˆå†…å®¹å¤±è´¥: {e}")
        
        # å¦‚æœAIç”Ÿæˆå¤±è´¥ï¼Œè¿”å›é«˜è´¨é‡é»˜è®¤å†…å®¹
        return self._get_fallback_content(content_type, platform, company_name, data_source)
    
    async def _get_content_topic(self, content_type: str, data_source: Dict[str, Any]) -> str:
        """æ ¹æ®å†…å®¹ç±»å‹ç”Ÿæˆå…·ä½“è¯é¢˜"""
        topics = {
            "knowledge": [
                "å›½é™…ç‰©æµDDPä¸DDUçš„åŒºåˆ«åŠé€‰æ‹©å»ºè®®",
                "æ¬§æ´²æ¸…å…³é¿å‘æŒ‡å—ï¼šè¿™äº›æ–‡ä»¶ä¸€å®šè¦å‡†å¤‡é½",
                "æµ·è¿ã€ç©ºè¿ã€é“è·¯æ€ä¹ˆé€‰ï¼Ÿä¸€å¼ è¡¨å¸®ä½ æå®š",
                "æ¬§æ´²VATé€’å»¶æ˜¯ä»€ä¹ˆï¼Ÿèƒ½å¸®ä½ çœå¤šå°‘é’±ï¼Ÿ",
                "FBAå¤´ç¨‹ç‰©æµå…¨æµç¨‹è§£æ",
                "è´§ç‰©ä¿é™©æ€ä¹ˆä¹°ï¼Ÿç†èµ”æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ"
            ],
            "pricing": [
                "æœ¬å‘¨æ¬§æ´²èˆªçº¿è¿ä»·é€ŸæŠ¥",
                "1æœˆæ¬§æ´²ç‰©æµè¿ä»·åˆ†æä¸å‘è´§å»ºè®®",
                "å¾·å›½/è·å…°/è‹±å›½æœ€æ–°è¿è´¹å¯¹æ¯”"
            ],
            "case": [
                "å®¢æˆ·æ¡ˆä¾‹ï¼šå¦‚ä½•å¸®åŠ©ç”µå­äº§å“å–å®¶èŠ‚çœ30%è¿è´¹",
                "çœŸå®æ¡ˆä¾‹ï¼šå¤„ç†æ¸…å…³å»¶è¯¯çš„ç´§æ€¥åº”å¯¹æ–¹æ¡ˆ",
                "æˆåŠŸæ¡ˆä¾‹ï¼šFBAå¤´ç¨‹+æµ·å¤–ä»“ä¸­è½¬ä¸€ç«™å¼æœåŠ¡"
            ],
            "policy": [
                "æ¬§ç›ŸCBAMç¢³å…³ç¨æ–°è§„è§£è¯»",
                "å¾·å›½åŒ…è£…æ³•æœ€æ–°è¦æ±‚",
                "è‹±å›½è„±æ¬§åæ¸…å…³æ–°å˜åŒ–"
            ],
            "faq": [
                "å®¢æˆ·æœ€å¸¸é—®çš„5ä¸ªç‰©æµé—®é¢˜è§£ç­”",
                "æ–°æ‰‹å¤–è´¸å¿…çœ‹ï¼šå›½é™…ç‰©æµQ&A",
                "å…³äºæ¸…å…³å’Œç¨è´¹ï¼Œä½ æƒ³çŸ¥é“çš„éƒ½åœ¨è¿™é‡Œ"
            ],
            "story": [
                "æˆ‘ä»¬ä¸ºä»€ä¹ˆä¸“æ³¨æ¬§æ´²ç‰©æµ15å¹´",
                "ä¸€ä¸ªåŒ…è£¹ä»æ·±åœ³åˆ°å¾·å›½çš„å…¨ç¨‹è®°å½•",
                "å®¢æˆ·å¥½è¯„èƒŒåçš„æ•…äº‹"
            ],
            "weekly": [
                "æœ¬å‘¨ç‰©æµåŠ¨æ€å›é¡¾ä¸ä¸‹å‘¨å±•æœ›",
                "ä¸€å‘¨è¡Œä¸šèµ„è®¯ç²¾é€‰"
            ]
        }
        
        import random
        type_topics = topics.get(content_type, ["ç‰©æµè¡Œä¸šå¹²è´§åˆ†äº«"])
        return random.choice(type_topics)
    
    def _get_type_specific_guide(self, content_type: str, data_source: Dict[str, Any]) -> str:
        """è·å–å†…å®¹ç±»å‹ä¸“é¡¹æŒ‡å¯¼"""
        guides = {
            "knowledge": """
- é€‰æ‹©1ä¸ªå…·ä½“çŸ¥è¯†ç‚¹æ·±å…¥è®²è§£
- ç”¨"é—®é¢˜â†’è§£ç­”â†’å®æ“å»ºè®®"çš„ç»“æ„
- åŠ å…¥çœŸå®æ¡ˆä¾‹æˆ–æ•°æ®ä½è¯
- æœ€åæ€»ç»“1-3ä¸ªå…³é”®è¦ç‚¹""",
            "pricing": """
- åˆ—å‡ºä¸»è¦èˆªçº¿çš„æœ€æ–°è¿ä»·
- å¯¹æ¯”æµ·è¿/ç©ºè¿/é“è·¯çš„ä»·æ ¼å’Œæ—¶æ•ˆ
- åˆ†æè¿‘æœŸå¸‚åœºè¶‹åŠ¿ï¼ˆæ¶¨/è·Œ/ç¨³ï¼‰
- ç»™å‡ºå‘è´§æ—¶æœºå»ºè®®""",
            "case": """
- æè¿°å®¢æˆ·èƒŒæ™¯å’Œç—›ç‚¹
- è¯´æ˜æä¾›çš„è§£å†³æ–¹æ¡ˆ
- å±•ç¤ºå…·ä½“æˆæœï¼ˆæ•°æ®åŒ–ï¼‰
- å¼•ç”¨å®¢æˆ·è¯„ä»·ï¼ˆå¯é€‚å½“è™šæ„ä½†è¦çœŸå®æ„Ÿï¼‰""",
            "policy": """
- ç®€è¿°æ”¿ç­–æ ¸å¿ƒå†…å®¹
- åˆ†æå¯¹ç‰©æµ/å¤–è´¸çš„å½±å“
- ç»™å‡ºåº”å¯¹å»ºè®®
- è¯´æ˜æˆ‘ä»¬èƒ½æä¾›çš„å¸®åŠ©""",
            "faq": """
- é€‰æ‹©3-5ä¸ªé«˜é¢‘é—®é¢˜
- ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€å›ç­”
- æ¯ä¸ªå›ç­”è¦æœ‰å®ç”¨ä»·å€¼
- å¯ä»¥å¼•å‡ºæ›´å¤šé—®é¢˜æ¿€å‘å’¨è¯¢""",
            "story": """
- è®²è¿°çœŸå®æ„Ÿäººçš„æœåŠ¡æ•…äº‹
- ä½“ç°å›¢é˜Ÿä¸“ä¸šå’Œç”¨å¿ƒ
- å±•ç¤ºå…¬å¸æ–‡åŒ–å’Œä»·å€¼è§‚
- è®©è¯»è€…äº§ç”Ÿæƒ…æ„Ÿå…±é¸£""",
            "weekly": """
- å›é¡¾æœ¬å‘¨è¡Œä¸šåŠ¨æ€
- åˆ†äº«æœ‰ä»·å€¼çš„ä¿¡æ¯
- å±•æœ›ä¸‹å‘¨å¸‚åœºè¶‹åŠ¿
- æ„Ÿè°¢å®¢æˆ·æ”¯æŒ"""
        }
        return guides.get(content_type, "- å†…å®¹è¦æœ‰ä»·å€¼ã€æœ‰å¹²è´§")
    
    def _get_platform_specific_guide(self, platform: str, content_type: str) -> str:
        """è·å–å¹³å°ä¸“é¡¹æŒ‡å¯¼"""
        guides = {
            "douyin": """
ğŸ“± æŠ–éŸ³çŸ­è§†é¢‘æ–‡æ¡ˆè¦æ±‚ï¼š
- å¼€å¤´5ç§’å¿…é¡»æœ‰é’©å­ï¼šç–‘é—®å¥ã€æ•°å­—ã€ç—›ç‚¹
- å…¨æ–‡å£è¯­åŒ–ï¼Œåƒåœ¨å’Œæœ‹å‹èŠå¤©
- åˆ†ç‚¹æ¸…æ™°ï¼Œæ¯ç‚¹ä¸€å¥è¯
- ç»“å°¾è¦æœ‰å¼ºäº’åŠ¨ï¼š"è¯„è®ºåŒºæ‰£1"ã€"å…³æ³¨ä¸è¿·è·¯"
- åŒæ—¶ç”Ÿæˆå®Œæ•´è§†é¢‘è„šæœ¬ï¼šåŒ…å«[æ—¶é—´]ã€ã€ç”»é¢ã€‘ã€ã€æ—ç™½ã€‘ã€ã€å­—å¹•ã€‘""",
            "xiaohongshu": """
ğŸ“• å°çº¢ä¹¦å›¾æ–‡è¦æ±‚ï¼š
- æ ‡é¢˜è¦æœ‰æ•°å­—ã€ç–‘é—®ã€emojiï¼ˆå¦‚"3ä¸ªæŠ€å·§"ã€"ä½ çŸ¥é“å—ï¼Ÿ"ï¼‰
- æ­£æ–‡åˆ†æ®µæ¸…æ™°ï¼Œæ¯æ®µ2-3å¥è¯
- å¤šç”¨emojiå¢åŠ é˜…è¯»æ„Ÿï¼ˆæ¯æ®µ1-2ä¸ªï¼‰
- è¯­æ°”äº²åˆ‡åƒé—ºèœœåˆ†äº«
- ç»“å°¾è¦æœ‰å¼•å¯¼æ”¶è—å’Œå…³æ³¨çš„è¯æœ¯""",
            "wechat_article": """
ğŸ“ å…¬ä¼—å·æ–‡ç« è¦æ±‚ï¼š
- æœ‰æ¸…æ™°çš„æ ‡é¢˜å±‚çº§ï¼ˆ##æ ‡é¢˜ ###å°æ ‡é¢˜ï¼‰
- å¼€å¤´æå‡ºé—®é¢˜æˆ–ç—›ç‚¹å¸å¼•é˜…è¯»
- æ­£æ–‡æœ‰æ•°æ®ã€æ¡ˆä¾‹ã€å¯¹æ¯”è¡¨æ ¼
- å¯ä»¥ç”¨å¼•ç”¨æ¡†çªå‡ºé‡ç‚¹
- ç»“å°¾æœ‰æ€»ç»“å’Œæ˜ç¡®çš„è¡ŒåŠ¨æŒ‡å¼•
- å†…å®¹ä¸“ä¸šä½†ä¸æ™¦æ¶©ï¼Œæœ‰æ·±åº¦æœ‰ä»·å€¼""",
            "wechat_moments": """
ğŸ’¬ æœ‹å‹åœˆæ–‡æ¡ˆè¦æ±‚ï¼š
- ä¸éœ€è¦æ ‡é¢˜ï¼Œç›´æ¥æ˜¯ç²¾ç‚¼æ–‡æ¡ˆ
- 3-5è¡Œä¸ºå®œï¼Œå¤ªé•¿æ²¡äººçœ‹
- è¦æœ‰æ¸©åº¦æ„Ÿï¼Œåƒæœ‹å‹åˆ†äº«
- å¯ä»¥é€‚å½“ç”¨emojiä½†ä¸è¦è¿‡å¤š
- ä¿¡æ¯å¯†åº¦é«˜ï¼Œæ¯å¥è¯éƒ½æœ‰ä»·å€¼
- ç»“å°¾ç®€å•å¼•å¯¼ç§ä¿¡å’¨è¯¢"""
        }
        return guides.get(platform, "- å†…å®¹è¦ç¬¦åˆå¹³å°è°ƒæ€§")
    
    def _get_video_script_requirement(self, platform: str) -> str:
        """è·å–è§†é¢‘è„šæœ¬è¦æ±‚è¯´æ˜"""
        if platform == "douyin":
            return "å¿…é¡»ç”Ÿæˆå®Œæ•´è§†é¢‘è„šæœ¬ï¼Œæ ¼å¼ï¼š[æ—¶é—´æ®µ] ã€ç”»é¢ã€‘xxx ã€æ—ç™½ã€‘xxx ã€å­—å¹•ã€‘xxx"
        return "ä»…æŠ–éŸ³éœ€è¦ï¼Œå…¶ä»–å¹³å°ç•™ç©ºå­—ç¬¦ä¸²"
    
    def _get_fallback_content(self, content_type: str, platform: str, company_name: str, data_source: Dict[str, Any]) -> Dict[str, Any]:
        """AIç”Ÿæˆå¤±è´¥æ—¶çš„å¤‡ç”¨é«˜è´¨é‡å†…å®¹"""
        company_info = data_source.get("company", {})
        advantages = company_info.get("advantages", ["15å¹´æ¬§æ´²ä¸“çº¿ç»éªŒ", "å¾·å›½/è·å…°æµ·å¤–ä»“", "å…¨å¢ƒDDU/DDPæœåŠ¡"])
        
        fallback_contents = {
            "douyin": {
                "title": "å‘è´§æ¬§æ´²ï¼Œè¿™3ä¸ªå‘åƒä¸‡åˆ«è¸©ï¼",
                "content": f"""åšå¤–è´¸çš„è€æ¿æ³¨æ„äº†ï¼å‘è´§æ¬§æ´²æœ€å®¹æ˜“è¸©çš„3ä¸ªå‘ï¼š

1ï¸âƒ£ è´ªä¾¿å®œé€‰æ²¡èµ„è´¨çš„è´§ä»£ï¼Œè´§ç‰©è¢«æ‰£æµ·å…³
2ï¸âƒ£ ä¸äº†è§£æ¸…å…³æ”¿ç­–ï¼ŒDDPå˜DDUè¿˜å¾—åŠ é’±
3ï¸âƒ£ æ²¡æœ‰æµ·å¤–ä»“æ”¯æŒï¼Œé€€æ¢è´§åªèƒ½é”€æ¯

{company_name}ï¼Œä¸“æ³¨æ¬§æ´²ç‰©æµ15å¹´âœ…
{chr(10).join(['âœ”ï¸ ' + adv for adv in advantages[:3]])}

éœ€è¦æ¬§æ´²ç‰©æµæŠ¥ä»·ï¼Ÿè¯„è®ºåŒºæ‰£1ï¼Œç§ä¿¡å‘ä½ ï¼""",
                "hashtags": ["æ¬§æ´²ç‰©æµ", "è·¨å¢ƒç”µå•†", "å¤–è´¸å¹²è´§", "å¾·å›½ä¸“çº¿", "ç‰©æµé¿å‘"],
                "call_to_action": "è¯„è®ºåŒºæ‰£1ï¼Œç§ä¿¡å‘ä½ ä¸“å±æŠ¥ä»·ï¼",
                "video_script": """[00:00-00:05] å¼€åœº
ã€ç”»é¢ã€‘å¿«é€’åŒ…è£¹è¢«æµ·å…³æ‰£æŠ¼çš„åœºæ™¯
ã€æ—ç™½ã€‘å‘è´§æ¬§æ´²ï¼Œè¿™3ä¸ªå‘è¸©äº†è¡€äºï¼
ã€å­—å¹•ã€‘æ¬§æ´²ç‰©æµé¿å‘æŒ‡å—

[00:05-00:20] å‘1
ã€ç”»é¢ã€‘ä»·æ ¼å¯¹æ¯”å›¾+æµ·å…³æŸ¥éªŒåœºæ™¯
ã€æ—ç™½ã€‘ç¬¬ä¸€å‘ï¼šè´ªä¾¿å®œé€‰æ²¡èµ„è´¨çš„è´§ä»£ï¼Œç»“æœè´§ç‰©è¢«æ‰£æµ·å…³ï¼ŒæŸå¤±æƒ¨é‡
ã€å­—å¹•ã€‘å‘1ï¼šè´ªä¾¿å®œ=é«˜é£é™©

[00:20-00:35] å‘2
ã€ç”»é¢ã€‘DDPå’ŒDDUå¯¹æ¯”åŠ¨ç”»
ã€æ—ç™½ã€‘ç¬¬äºŒå‘ï¼šä¸äº†è§£æ¸…å…³æ”¿ç­–ï¼Œè¯´å¥½çš„DDPï¼Œåˆ°äº†å˜DDUï¼Œè¿˜å¾—é¢å¤–åŠ é’±
ã€å­—å¹•ã€‘å‘2ï¼šæä¸æ‡‚DDP/DDU

[00:35-00:50] å‘3
ã€ç”»é¢ã€‘è´§ç‰©é”€æ¯åœºæ™¯
ã€æ—ç™½ã€‘ç¬¬ä¸‰å‘ï¼šæ²¡æœ‰æµ·å¤–ä»“æ”¯æŒï¼Œå®¢æˆ·é€€è´§åªèƒ½é”€æ¯ï¼Œç™½ç™½æŸå¤±
ã€å­—å¹•ã€‘å‘3ï¼šæ— æµ·å¤–ä»“æ”¯æ’‘

[00:50-01:00] è§£å†³æ–¹æ¡ˆ+CTA
ã€ç”»é¢ã€‘å…¬å¸logo+æœåŠ¡ä¼˜åŠ¿å±•ç¤º
ã€æ—ç™½ã€‘15å¹´æ¬§æ´²ä¸“çº¿ï¼Œå¾·å›½è·å…°è‡ªæœ‰ä»“ï¼Œä¸“ä¸šæ¸…å…³ï¼Œè®©ä½ å‘è´§æ— å¿§ï¼è¯„è®ºæ‰£1ï¼Œç§ä¿¡å‘æŠ¥ä»·ï¼
ã€å­—å¹•ã€‘{company_name} | æ¬§æ´²ç‰©æµä¸“å®¶"""
            },
            "xiaohongshu": {
                "title": "å‘è´§æ¬§æ´²è¸©è¿‡çš„å‘ï¼Œå¸Œæœ›ä½ åˆ«å†è¸©äº†ğŸ˜­",
                "content": f"""åšè·¨å¢ƒ3å¹´ï¼Œåœ¨ç‰©æµä¸Šåƒè¿‡çš„äºå¤ªå¤šäº†ï¼Œä»Šå¤©åˆ†äº«ç»™å§å¦¹ä»¬é¿é¿é›·ğŸ’¡

âŒ å‘1ï¼šè´ªä¾¿å®œé€‰å°è´§ä»£
ä¹‹å‰ä¸ºäº†çœ200å—é€‰äº†ä¸ªæ²¡å¬è¿‡çš„è´§ä»£ï¼Œç»“æœè´§åœ¨æµ·å…³èººäº†2å‘¨ï¼Œå®¢æˆ·ç›´æ¥å–æ¶ˆè®¢å•ï¼Œäºå¤§äº†ğŸ˜±

âŒ å‘2ï¼šDDPâ‰ çœŸåŒ…ç¨
æœ‰äº›æ‰€è°“"DDPæœåŠ¡"å…¶å®æ˜¯åŠåŒ…ï¼Œå°¾ç¨‹å…³ç¨è¿˜å¾—è‡ªå·±æï¼Œå¥—è·¯æ»¡æ»¡âš ï¸

âŒ å‘3ï¼šæ²¡æœ‰æµ·å¤–ä»“
é€€è´§åªèƒ½é”€æ¯æˆ–è€…é«˜ä»·é€€å›å›½ï¼Œä¸€å•äºå‡ åƒå—ğŸ’¸

åæ¥æ‰¾åˆ°äº†{company_name}ï¼ŒçœŸçš„é è°±ğŸ‘‡
âœ… {advantages[0] if len(advantages) > 0 else '15å¹´æ¬§æ´²ä¸“çº¿ç»éªŒ'}
âœ… {advantages[1] if len(advantages) > 1 else 'å¾·å›½/è·å…°è‡ªæœ‰æµ·å¤–ä»“'}
âœ… {advantages[2] if len(advantages) > 2 else 'å…¨å¢ƒDDU/DDPæœåŠ¡'}
âœ… ä¸€å¯¹ä¸€å®¢æœï¼Œæœ‰é—®é¢˜ç§’å›

ç°åœ¨å‘è´§æ¬§æ´²å†ä¹Ÿä¸ç„¦è™‘äº†âœ¨

ğŸ“© éœ€è¦æŠ¥ä»·çš„å§å¦¹ç§ä¿¡æˆ‘ï¼Œå¤‡æ³¨"å°çº¢ä¹¦"ä¼˜å…ˆå›å¤ï½""",
                "hashtags": ["è·¨å¢ƒç‰©æµ", "æ¬§æ´²ä¸“çº¿", "å¤–è´¸å¹²è´§", "ç‰©æµé¿å‘", "äºšé©¬é€ŠFBA"],
                "call_to_action": "ç§ä¿¡æˆ‘é¢†å–ä¸“å±æŠ¥ä»·æ–¹æ¡ˆï¼Œå¤‡æ³¨"å°çº¢ä¹¦"ä¼˜å…ˆå›å¤ï½",
                "video_script": ""
            },
            "wechat_article": {
                "title": f"ã€å¹²è´§ã€‘æ¬§æ´²ç‰©æµé¿å‘æŒ‡å—ï¼šé€‰å¯¹åˆä½œä¼™ä¼´çœå¿ƒçœé’±",
                "content": f"""åœ¨è·¨å¢ƒç”µå•†è“¬å‹ƒå‘å±•çš„ä»Šå¤©ï¼Œæ¬§æ´²å¸‚åœºä»¥å…¶é«˜æ¶ˆè´¹åŠ›å’Œç¨³å®šéœ€æ±‚æˆä¸ºä¼—å¤šå–å®¶çš„å¿…äº‰ä¹‹åœ°ã€‚ç„¶è€Œï¼Œç‰©æµç¯èŠ‚çš„å¤æ‚æ€§å¸¸å¸¸è®©äººå¤´ç–¼â€”â€”æ¸…å…³å»¶è¯¯ã€ç¨è´¹ä¸é€æ˜ã€é€€è´§å¤„ç†å›°éš¾ç­‰é—®é¢˜å±‚å‡ºä¸ç©·ã€‚

ä½œä¸ºæ·±è€•æ¬§æ´²ç‰©æµ15å¹´çš„{company_name}ï¼Œæˆ‘ä»¬è§è¯äº†å¤ªå¤šå–å®¶åœ¨ç‰©æµé€‰æ‹©ä¸Šçš„å›°æƒ‘ä¸æ•™è®­ã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬å°†è¿™äº›ç»éªŒæ€»ç»“æˆæ–‡ï¼Œå¸Œæœ›èƒ½å¸®åŠ©æ‚¨å°‘èµ°å¼¯è·¯ã€‚

## ä¸€ã€é€‰æ‹©ç‰©æµæœåŠ¡å•†çš„3å¤§æ ¸å¿ƒè€ƒé‡

### 1. èµ„è´¨ä¸ç»éªŒ
ä¸“ä¸šçš„ç‰©æµæœåŠ¡å•†åº”å…·å¤‡å®Œå–„çš„æ¸…å…³èµ„è´¨å’Œä¸°å¯Œçš„æ¬§æ´²å¸‚åœºç»éªŒã€‚{company_name}æ‹¥æœ‰{advantages[0] if len(advantages) > 0 else '15å¹´æ¬§æ´²ä¸“çº¿è¿è¥ç»éªŒ'}ï¼Œç†Ÿæ‚‰å¾·å›½ã€è·å…°ã€è‹±å›½ã€æ³•å›½ç­‰å›½çš„æµ·å…³æ”¿ç­–å’Œæ“ä½œæµç¨‹ã€‚

### 2. æœåŠ¡æ¨¡å¼é€æ˜åº¦
DDPï¼ˆå®Œç¨åäº¤è´§ï¼‰å’ŒDDUï¼ˆæœªå®Œç¨äº¤è´§ï¼‰æ˜¯ä¸¤ç§å¸¸è§çš„è´¸æ˜“æœ¯è¯­ï¼ŒåŠ¡å¿…åœ¨åˆä½œå‰æ˜ç¡®æœåŠ¡èŒƒå›´ã€‚æˆ‘ä»¬æä¾›çš„{advantages[2] if len(advantages) > 2 else 'å…¨å¢ƒDDU/DDPæœåŠ¡'}ï¼ŒæŠ¥ä»·å³åŒ…å«æ‰€æœ‰è´¹ç”¨ï¼Œæ— éšå½¢æ”¶è´¹ã€‚

### 3. æµ·å¤–ä»“å‚¨èƒ½åŠ›
{advantages[1] if len(advantages) > 1 else 'å¾·å›½/è·å…°è‡ªæœ‰æµ·å¤–ä»“'}èƒ½æœ‰æ•ˆè§£å†³é€€æ¢è´§éš¾é¢˜ï¼ŒåŒæ—¶æ”¯æŒæœ¬åœ°åŒ–åˆ†æ‹¨ï¼Œæå‡é…é€æ—¶æ•ˆã€‚

## äºŒã€æˆ‘ä»¬çš„æœåŠ¡ä¼˜åŠ¿

{chr(10).join(['- ' + adv for adv in advantages])}
- ä¸€å¯¹ä¸€ä¸“å±å®¢æœï¼Œå…¨ç¨‹å¯è§†åŒ–è¿½è¸ª

## ä¸‰ã€åˆä½œæµç¨‹

1. **éœ€æ±‚æ²Ÿé€š**ï¼šäº†è§£æ‚¨çš„è´§ç‰©ç±»å‹ã€ç›®çš„åœ°ã€æ—¶æ•ˆè¦æ±‚
2. **æ–¹æ¡ˆå®šåˆ¶**ï¼šæä¾›æµ·è¿/ç©ºè¿/é“è·¯å¤šç§æ–¹æ¡ˆå¯¹æ¯”
3. **æŠ¥ä»·ç¡®è®¤**ï¼šé€æ˜æŠ¥ä»·ï¼Œæ— éšå½¢è´¹ç”¨
4. **æ‰§è¡Œäº¤ä»˜**ï¼šå…¨ç¨‹è·Ÿè¸ªï¼ŒåŠæ—¶åé¦ˆ

---

**å¦‚æœæ‚¨æ­£åœ¨å¯»æ‰¾å¯é çš„æ¬§æ´²ç‰©æµåˆä½œä¼™ä¼´ï¼Œæ¬¢è¿è”ç³»æˆ‘ä»¬è·å–ä¸“å±æŠ¥ä»·æ–¹æ¡ˆã€‚**

é¦–æ¬¡åˆä½œå®¢æˆ·å¯äº«å—è¿è´¹ä¼˜æƒ ï¼Œåé¢æœ‰é™ï¼Œå…ˆåˆ°å…ˆå¾—ã€‚""",
                "hashtags": ["å›½é™…ç‰©æµ", "æ¬§æ´²ä¸“çº¿", "è·¨å¢ƒç”µå•†ç‰©æµ", "DDPæ¸…å…³", "æµ·å¤–ä»“"],
                "call_to_action": "ç‚¹å‡»é˜…è¯»åŸæ–‡æˆ–æ·»åŠ å®¢æœå¾®ä¿¡ï¼Œè·å–æ‚¨çš„ä¸“å±ç‰©æµè§£å†³æ–¹æ¡ˆï¼",
                "video_script": ""
            },
            "wechat_moments": {
                "title": "",
                "content": f"""ğŸ“¦ å‘è´§æ¬§æ´²çš„è€æ¿çœ‹è¿‡æ¥

{company_name}ï¼Œä¸“æ³¨æ¬§æ´²ç‰©æµ15å¹´
âœ… {advantages[0] if len(advantages) > 0 else 'å¾·å›½/è·å…°/è‹±å›½/æ³•å›½å…¨å¢ƒè¦†ç›–'}
âœ… {advantages[1] if len(advantages) > 1 else 'DDU/DDPåŒæ¨¡å¼ï¼ŒæŠ¥ä»·é€æ˜'}
âœ… {advantages[2] if len(advantages) > 2 else 'æµ·å¤–ä»“æ”¯æŒï¼Œé€€æ¢æ— å¿§'}

æœ€è¿‘æ¬§æ´²èˆªçº¿èˆ±ä½ç´§å¼ ï¼Œå»ºè®®æå‰é¢„è®¢
éœ€è¦æŠ¥ä»·çš„è€æ¿ç§ä¿¡æˆ‘ ğŸ‘‡""",
                "hashtags": ["æ¬§æ´²ç‰©æµ", "è·¨å¢ƒç”µå•†"],
                "call_to_action": "éœ€è¦æŠ¥ä»·ç§ä¿¡æˆ‘",
                "video_script": ""
            }
        }
        
        return fallback_contents.get(platform, fallback_contents["wechat_moments"])
    
    def _extract_variables(self, data_source: Dict[str, Any]) -> Dict[str, str]:
        """ä»æ•°æ®æºæå–å˜é‡"""
        variables = {
            "month": str(datetime.now().month),
            "year": str(datetime.now().year),
            "date": datetime.now().strftime("%Y-%m-%d"),
        }
        
        # å…¬å¸ä¿¡æ¯
        if "company" in data_source:
            variables["company_name"] = data_source["company"].get("name", "ç‰©æµå…¬å¸")
        
        # è¿ä»·ä¿¡æ¯
        if "pricing" in data_source:
            pricing = data_source["pricing"]
            if isinstance(pricing, dict):
                sea = pricing.get("sea_freight", [])
                if sea and len(sea) > 0:
                    variables["destination"] = sea[0].get("route", "æ¬§æ´²").split("â†’")[-1].strip()
                    variables["price"] = str(sea[0].get("price", 2500))
                    variables["transit_time"] = sea[0].get("transit_time", "25-30å¤©")
        
        return variables
    
    def _replace_variables(self, template: str, variables: Dict[str, str]) -> str:
        """æ›¿æ¢æ¨¡æ¿ä¸­çš„å˜é‡"""
        result = template
        for key, value in variables.items():
            result = result.replace(f"{{{key}}}", str(value))
        return result
    
    def _build_data_summary(self, content_type: str, data_source: Dict[str, Any]) -> str:
        """æ„å»ºè¯¦ç»†çš„æ•°æ®æ‘˜è¦ä¾›AIä½¿ç”¨"""
        lines = []
        
        # å…¬å¸åŸºæœ¬ä¿¡æ¯
        if "company" in data_source:
            company = data_source["company"]
            if company.get("name"):
                lines.append(f"### å…¬å¸ä¿¡æ¯")
                lines.append(f"- å…¬å¸åç§°ï¼š{company['name']}")
                if company.get("intro"):
                    lines.append(f"- å…¬å¸ç®€ä»‹ï¼š{company['intro']}")
                if company.get("advantages"):
                    lines.append(f"- æ ¸å¿ƒä¼˜åŠ¿ï¼š{', '.join(company['advantages'])}")
        
        # æ ¹æ®å†…å®¹ç±»å‹æ·»åŠ ä¸“é¡¹æ•°æ®
        if content_type == "pricing" and "pricing" in data_source:
            pricing = data_source["pricing"]
            if isinstance(pricing, dict):
                lines.append("\n### æœ€æ–°è¿ä»·æ•°æ®ï¼ˆå¯ç›´æ¥å¼•ç”¨ï¼‰")
                
                # æµ·è¿è¿ä»·
                sea_freight = pricing.get("sea_freight", [])
                if sea_freight:
                    lines.append("\n**æµ·è¿æ•´æŸœè¿ä»·ï¼š**")
                    for item in sea_freight[:5]:
                        route = item.get('route', '')
                        price = item.get('price', 0)
                        container = item.get('container_type', '40GP')
                        time = item.get('transit_time', '')
                        remarks = item.get('remarks', '')
                        lines.append(f"- {route}: ${price}/{container}, æ—¶æ•ˆ{time}")
                        if remarks:
                            lines.append(f"  å¤‡æ³¨ï¼š{remarks}")
                
                # ç©ºè¿è¿ä»·
                air_freight = pricing.get("air_freight", [])
                if air_freight:
                    lines.append("\n**ç©ºè¿è¿ä»·ï¼š**")
                    for item in air_freight[:3]:
                        route = item.get('route', '')
                        price = item.get('price_per_kg', 0)
                        time = item.get('transit_time', '')
                        lines.append(f"- {route}: Â¥{price}/kg, æ—¶æ•ˆ{time}")
                
                # é“è·¯è¿ä»·
                rail_freight = pricing.get("rail_freight", [])
                if rail_freight:
                    lines.append("\n**ä¸­æ¬§ç­åˆ—è¿ä»·ï¼š**")
                    for item in rail_freight[:2]:
                        route = item.get('route', '')
                        price = item.get('price', 0)
                        time = item.get('transit_time', '')
                        lines.append(f"- {route}: ${price}/æŸœ, æ—¶æ•ˆ{time}")
                
                # å¸‚åœºåŠ¨æ€
                if pricing.get("highlight"):
                    lines.append(f"\n**å¸‚åœºåŠ¨æ€ï¼š**{pricing['highlight']}")
                if pricing.get("service_area"):
                    lines.append(f"**æœåŠ¡åŒºåŸŸï¼š**{pricing['service_area']}")
        
        elif content_type == "case" and "cases" in data_source:
            cases = data_source["cases"]
            if cases:
                lines.append("\n### çœŸå®å®¢æˆ·æ¡ˆä¾‹ï¼ˆå¯å¼•ç”¨æˆ–æ”¹ç¼–ï¼‰")
                for i, case in enumerate(cases[:3], 1):
                    lines.append(f"\n**æ¡ˆä¾‹{i}ï¼š**")
                    lines.append(f"- å®¢æˆ·ç±»å‹ï¼š{case.get('customer_type', 'è·¨å¢ƒå–å®¶')}")
                    lines.append(f"- è´§ç‰©ç±»å‹ï¼š{case.get('cargo_type', 'ä¸€èˆ¬è´¸æ˜“è´§ç‰©')}")
                    lines.append(f"- è¿è¾“è·¯çº¿ï¼š{case.get('route', 'ä¸­å›½åˆ°æ¬§æ´²')}")
                    lines.append(f"- æœåŠ¡æ–¹æ¡ˆï¼š{case.get('service', 'æµ·è¿+æ¸…å…³+æ´¾é€')}")
                    lines.append(f"- äº®ç‚¹æˆæœï¼š{case.get('highlight', 'å‡†æ—¶é€è¾¾')}")
                    if case.get('feedback'):
                        lines.append(f"- å®¢æˆ·åé¦ˆï¼š"{case['feedback']}"")
        
        elif content_type == "policy" and "policy" in data_source:
            policy = data_source["policy"]
            if policy:
                lines.append("\n### æ”¿ç­–ä¿¡æ¯ï¼ˆç”¨äºè§£è¯»ï¼‰")
                lines.append(f"- æ”¿ç­–ä¸»é¢˜ï¼š{policy.get('title', '')}")
                lines.append(f"- æ”¿ç­–æ‘˜è¦ï¼š{policy.get('summary', '')}")
                if policy.get("key_points"):
                    lines.append("- å…³é”®è¦ç‚¹ï¼š")
                    for point in policy.get("key_points", [])[:5]:
                        lines.append(f"  â€¢ {point}")
                if policy.get("impact"):
                    lines.append(f"- å½±å“åˆ†æï¼š{policy['impact']}")
                if policy.get("recommendation"):
                    lines.append(f"- åº”å¯¹å»ºè®®ï¼š{policy['recommendation']}")
        
        elif content_type == "faq" and "faq" in data_source:
            faq = data_source["faq"]
            if faq:
                lines.append("\n### å®¢æˆ·é«˜é¢‘é—®é¢˜ï¼ˆç”¨äºè§£ç­”ï¼‰")
                for i, q in enumerate(faq[:6], 1):
                    lines.append(f"{i}. {q}")
        
        elif content_type == "weekly" and "weekly_stats" in data_source:
            stats = data_source["weekly_stats"]
            if stats:
                lines.append("\n### æœ¬å‘¨ä¸šåŠ¡æ•°æ®")
                lines.append(f"- æ–°å¢å®¢æˆ·ï¼š{stats.get('new_customers', 0)}å®¶")
                lines.append(f"- æ–°å¢çº¿ç´¢ï¼š{stats.get('new_leads', 0)}æ¡")
                if stats.get("highlight"):
                    lines.append(f"- å‘¨æŠ¥äº®ç‚¹ï¼š{stats['highlight']}")
        
        elif content_type == "story":
            lines.append("\n### å…¬å¸æ•…äº‹ç´ æ")
            lines.append("- åˆ›ä¸šå†ç¨‹ï¼š15å¹´å‰ä»æ¬§æ´²ä¸“çº¿èµ·æ­¥ï¼Œä¸“æ³¨åšå¥½ä¸€ä»¶äº‹")
            lines.append("- å›¢é˜Ÿç†å¿µï¼šå®¢æˆ·çš„è´§å°±æ˜¯æˆ‘ä»¬çš„è´£ä»»")
            lines.append("- æœåŠ¡æ‰¿è¯ºï¼šå…¨ç¨‹å¯è§†ã€é—®é¢˜å¿…è¾¾ã€å”®åæ— å¿§")
            lines.append("- é‡Œç¨‹ç¢‘ï¼šç´¯è®¡æœåŠ¡å®¢æˆ·3000+å®¶ï¼Œ0é‡å¤§æ¸…å…³äº‹æ•…")
        
        elif content_type == "knowledge":
            lines.append("\n### ç‰©æµçŸ¥è¯†è¦ç‚¹ï¼ˆä¾›å‚è€ƒï¼‰")
            lines.append("- DDPï¼ˆå®Œç¨åäº¤è´§ï¼‰ï¼šå–æ–¹æ‰¿æ‹…å…¨éƒ¨è´¹ç”¨å’Œé£é™©ï¼Œä¹°æ–¹åªéœ€æ”¶è´§")
            lines.append("- DDUï¼ˆæœªå®Œç¨äº¤è´§ï¼‰ï¼šå–æ–¹é€è´§åˆ°ç›®çš„åœ°ï¼Œä½†ä¹°æ–¹è´Ÿè´£æ¸…å…³å’Œç¨è´¹")
            lines.append("- æ¬§æ´²ä¸»è¦æ¸¯å£ï¼šæ±‰å ¡(å¾·å›½)ã€é¹¿ç‰¹ä¸¹(è·å…°)ã€è´¹åˆ©å…‹æ–¯æ‰˜(è‹±å›½)ã€å‹’é˜¿å¼—å°”(æ³•å›½)")
            lines.append("- æ—¶æ•ˆå‚è€ƒï¼šæµ·è¿28-35å¤©ï¼Œç©ºè¿5-7å¤©ï¼Œä¸­æ¬§ç­åˆ—18-22å¤©")
            lines.append("- æ¸…å…³è¦ç‚¹ï¼šå‘ç¥¨ã€è£…ç®±å•ã€æå•ã€åŸäº§åœ°è¯ã€CEè®¤è¯ç­‰")
        
        # æ·»åŠ é€šç”¨çš„è¥é”€é’©å­å»ºè®®
        lines.append("\n### è¥é”€é’©å­å»ºè®®")
        lines.append("- å…è´¹å’¨è¯¢ã€ä¸“å±æŠ¥ä»·ã€ä¸€å¯¹ä¸€æœåŠ¡")
        lines.append("- 15å¹´ç»éªŒã€3000+å®¢æˆ·ã€0é‡å¤§äº‹æ•…")
        lines.append("- é™æ—¶ä¼˜æƒ ã€åé¢æœ‰é™ã€å…ˆåˆ°å…ˆå¾—")
        
        return "\n".join(lines) if lines else "è¯·åŸºäºç‰©æµè¡Œä¸šä¸“ä¸šçŸ¥è¯†ç”Ÿæˆå†…å®¹ï¼Œçªå‡ºæ¬§æ´²ä¸“çº¿æœåŠ¡ä¼˜åŠ¿"
    
    # ==================== æ¨¡æ‹Ÿæ•°æ®ï¼ˆç­‰ERPå¯¹æ¥åæ›¿æ¢ï¼‰ ====================
    
    async def _get_mock_pricing_data(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿè¿ä»·æ•°æ® - ä»…æ¬§æ´²èˆªçº¿"""
        return {
            "sea_freight": [
                {
                    "route": "æ·±åœ³ â†’ æ±‰å ¡(å¾·å›½)",
                    "container_type": "40GP",
                    "price": 2500,
                    "currency": "USD",
                    "transit_time": "28-32å¤©",
                    "remarks": "æœ¬å‘¨èˆ±ä½å……è¶³ï¼Œå¾·å›½å…¨å¢ƒæ´¾é€"
                },
                {
                    "route": "å®æ³¢ â†’ é¹¿ç‰¹ä¸¹(è·å…°)",
                    "container_type": "40HQ",
                    "price": 2800,
                    "currency": "USD",
                    "transit_time": "25-30å¤©",
                    "remarks": "è·å…°ä»“å‚¨+æ¬§æ´²å…¨å¢ƒåˆ†æ‹¨"
                },
                {
                    "route": "ä¸Šæµ· â†’ è´¹åˆ©å…‹æ–¯æ‰˜(è‹±å›½)",
                    "container_type": "40GP",
                    "price": 2600,
                    "currency": "USD",
                    "transit_time": "30-35å¤©",
                    "remarks": "å«æ¸…å…³ï¼ŒDDPåˆ°é—¨"
                },
                {
                    "route": "æ·±åœ³ â†’ å‹’é˜¿å¼—å°”(æ³•å›½)",
                    "container_type": "40GP",
                    "price": 2700,
                    "currency": "USD",
                    "transit_time": "30-35å¤©",
                    "remarks": "æ³•å›½å…¨å¢ƒæ´¾é€"
                },
                {
                    "route": "å®æ³¢ â†’ çƒ­é‚£äºš(æ„å¤§åˆ©)",
                    "container_type": "40GP",
                    "price": 2900,
                    "currency": "USD",
                    "transit_time": "32-38å¤©",
                    "remarks": "æ„å¤§åˆ©æ¸…å…³ä¸€æ¡é¾™"
                }
            ],
            "air_freight": [
                {
                    "route": "æ·±åœ³ â†’ æ³•å…°å…‹ç¦(å¾·å›½)",
                    "price_per_kg": 28,
                    "currency": "CNY",
                    "transit_time": "5-7å¤©",
                    "min_weight": 45,
                    "remarks": "ç´§æ€¥ä»¶é¦–é€‰"
                },
                {
                    "route": "ä¸Šæµ· â†’ é˜¿å§†æ–¯ç‰¹ä¸¹(è·å…°)",
                    "price_per_kg": 30,
                    "currency": "CNY",
                    "transit_time": "4-6å¤©",
                    "min_weight": 45
                }
            ],
            "rail_freight": [
                {
                    "route": "ä¹‰ä¹Œ â†’ æœä¼Šæ–¯å ¡(å¾·å›½)",
                    "container_type": "40GP",
                    "price": 8500,
                    "currency": "USD",
                    "transit_time": "18-22å¤©",
                    "remarks": "ä¸­æ¬§ç­åˆ—ï¼Œæ€§ä»·æ¯”ä¹‹é€‰"
                },
                {
                    "route": "æˆéƒ½ â†’ æ³¢å…°åæ²™",
                    "container_type": "40GP",
                    "price": 7800,
                    "currency": "USD",
                    "transit_time": "15-18å¤©"
                }
            ],
            "highlight": "æœ¬å‘¨æ¬§æ´²èˆªçº¿è¿ä»·å¹³ç¨³ï¼Œå¾·å›½/è·å…°çº¿èˆ±ä½å……è¶³ï¼Œå»ºè®®æå‰é¢„è®¢",
            "service_area": "ä¸“æ³¨æ¬§æ´²ï¼šå¾·å›½ã€è·å…°ã€è‹±å›½ã€æ³•å›½ã€æ„å¤§åˆ©ã€è¥¿ç­ç‰™ã€æ³¢å…°ç­‰"
        }
    
    async def _get_mock_case_data(self) -> List[Dict[str, Any]]:
        """æ¨¡æ‹Ÿæ¡ˆä¾‹æ•°æ® - ä»…æ¬§æ´²å®¢æˆ·"""
        return [
            {
                "customer_type": "è·¨å¢ƒç”µå•†å–å®¶",
                "cargo_type": "ç”µå­äº§å“",
                "route": "æ·±åœ³ â†’ å¾·å›½FBAä»“",
                "service": "æµ·è¿+å¾·å›½æ¸…å…³+äºšé©¬é€Šä»“æ´¾é€",
                "highlight": "28å¤©åˆ°ä»“ï¼Œå«æ¸…å…³å’ŒVATé€’å»¶",
                "feedback": "å¾·å›½çº¿åšäº†3å¹´äº†ï¼Œæ¯æ¬¡éƒ½å¾ˆç¨³"
            },
            {
                "customer_type": "å¤–è´¸å·¥å‚",
                "cargo_type": "æœºæ¢°é…ä»¶",
                "route": "å®æ³¢ â†’ è‹±å›½ä¼¯æ˜ç¿°",
                "service": "æ•´æŸœæµ·è¿DDPåˆ°é—¨",
                "highlight": "å¸®å®¢æˆ·èŠ‚çœäº†30%è¿è´¹ï¼Œå«è‹±å›½æ¸…å…³",
                "feedback": "è‹±å›½è„±æ¬§åæ¸…å…³éº»çƒ¦ï¼Œä»–ä»¬æå®šäº†"
            },
            {
                "customer_type": "å®¶å…·å‡ºå£å•†",
                "cargo_type": "å®æœ¨å®¶å…·",
                "route": "ä½›å±± â†’ è·å…°é¹¿ç‰¹ä¸¹",
                "service": "æµ·è¿+è·å…°ä»“å‚¨+æ¬§æ´²åˆ†æ‹¨",
                "highlight": "è·å…°ä»“ä¸­è½¬ï¼Œè¦†ç›–æ¬§æ´²5å›½å®¢æˆ·",
                "feedback": "ä»“å‚¨è´¹ç”¨æ¯”å…¶ä»–ä½ï¼ŒæœåŠ¡ä¹Ÿä¸“ä¸š"
            },
            {
                "customer_type": "æœè£…å“ç‰Œå•†",
                "cargo_type": "æœè£…é‹å¸½",
                "route": "ä¹‰ä¹Œ â†’ æ³¢å…°åæ²™",
                "service": "ä¸­æ¬§ç­åˆ—+æ³¢å…°æ¸…å…³",
                "highlight": "é“è·¯æ¯”æµ·è¿å¿«10å¤©ï¼Œæ¯”ç©ºè¿çœä¸€åŠ",
                "feedback": "ä¸œæ¬§å¸‚åœºå°±é è¿™æ¡çº¿æ”¯æ’‘"
            }
        ]
    
    async def _get_mock_policy_data(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ”¿ç­–æ•°æ® - æ¬§æ´²æ”¿ç­–"""
        return {
            "title": "æ¬§ç›ŸCBAMç¢³å…³ç¨æ–°è§„è§£è¯»",
            "summary": "è‡ª2026å¹´èµ·ï¼Œè¿›å£æ¬§ç›Ÿçš„é’¢é“ã€é“ç­‰äº§å“éœ€ç”³æŠ¥ç¢³æ’æ”¾",
            "key_points": [
                "é€‚ç”¨äº§å“èŒƒå›´ï¼šé’¢é“ã€é“ã€æ°´æ³¥ã€åŒ–è‚¥ã€ç”µåŠ›",
                "éœ€è¦æä¾›ç¢³æ’æ”¾æ•°æ®è¯æ˜",
                "è¿‡æ¸¡æœŸæŠ¥å‘Šä¹‰åŠ¡å·²å¼€å§‹",
                "2026å¹´æ­£å¼å¾æ”¶ç¢³å…³ç¨"
            ],
            "impact": "å¯¹ç”µå­äº§å“å½±å“è¾ƒå°ï¼Œé’¢é“é“æå‡ºå£æ¬§æ´²éœ€é‡ç‚¹å…³æ³¨",
            "recommendation": "å»ºè®®ä¸ä¾›åº”å•†ç¡®è®¤ç¢³æ’æ”¾æ•°æ®ï¼Œæˆ‘ä»¬å¯ååŠ©å‡†å¤‡ç”³æŠ¥ææ–™",
            "related_policies": [
                "å¾·å›½åŒ…è£…æ³•VerpackGæ³¨å†Œè¦æ±‚",
                "æ¬§ç›ŸWEEEç”µå­åºŸå¼ƒç‰©å›æ”¶æ³•è§„",
                "è‹±å›½è„±æ¬§åæ¸…å…³æ–°è§„",
                "æ¬§ç›ŸCEè®¤è¯æ›´æ–°è¦æ±‚"
            ],
            "service_area": "æ¬§æ´²"
        }
    
    async def _extract_faq_from_conversations(self, db) -> List[str]:
        """ä»å®¢æˆ·å¯¹è¯ä¸­æå–é«˜é¢‘é—®é¢˜"""
        # ç®€å•å®ç°ï¼šä»å¯¹è¯ä¸­æå–åŒ…å«é—®å·çš„å†…å®¹
        try:
            result = await db.execute(
                text("""
                    SELECT content FROM conversations 
                    WHERE message_type = 'inbound' 
                    AND content LIKE '%ï¼Ÿ%'
                    ORDER BY created_at DESC
                    LIMIT 20
                """)
            )
            rows = result.fetchall()
            
            questions = []
            for row in rows:
                content = row[0]
                if 'ï¼Ÿ' in content or '?' in content:
                    # ç®€å•æ¸…ç†
                    q = content.strip()
                    if len(q) > 10 and len(q) < 100:
                        questions.append(q)
            
            return questions[:5] if questions else [
                "æµ·è¿åˆ°å¾·å›½è¦å¤šä¹…ï¼Ÿ",
                "æ¬§æ´²æ¸…å…³éœ€è¦ä»€ä¹ˆèµ„æ–™ï¼Ÿ",
                "å¾·å›½FBAä»“æ´¾é€æ€ä¹ˆæ”¶è´¹ï¼Ÿ",
                "ä¸­æ¬§ç­åˆ—å’Œæµ·è¿æ€ä¹ˆé€‰ï¼Ÿ",
                "è‹±å›½è„±æ¬§åæ¸…å…³æœ‰ä»€ä¹ˆå˜åŒ–ï¼Ÿ"
            ]
        except:
            return [
                "æµ·è¿åˆ°å¾·å›½è¦å¤šä¹…ï¼Ÿ",
                "æ¬§æ´²DDUå’ŒDDPæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
                "è·å…°ä»“å¯ä»¥åˆ†æ‹¨åˆ°å“ªäº›å›½å®¶ï¼Ÿ"
            ]
    
    async def _get_weekly_stats(self, db) -> Dict[str, Any]:
        """è·å–æœ¬å‘¨ç»Ÿè®¡æ•°æ®"""
        try:
            # æœ¬å‘¨æ–°å®¢æˆ·
            result = await db.execute(
                text("""
                    SELECT COUNT(*) FROM customers 
                    WHERE created_at >= DATE_TRUNC('week', CURRENT_DATE)
                """)
            )
            new_customers = result.scalar() or 0
            
            # æœ¬å‘¨çº¿ç´¢
            result = await db.execute(
                text("""
                    SELECT COUNT(*) FROM leads 
                    WHERE created_at >= DATE_TRUNC('week', CURRENT_DATE)
                """)
            )
            new_leads = result.scalar() or 0
            
            return {
                "new_customers": new_customers,
                "new_leads": new_leads,
                "highlight": "æœ¬å‘¨ä¸šåŠ¡ç¨³æ­¥å¢é•¿"
            }
        except:
            return {
                "new_customers": 0,
                "new_leads": 0,
                "highlight": "æ„Ÿè°¢å¤§å®¶çš„æ”¯æŒ"
            }
    
    # ==================== æŸ¥è¯¢æ–¹æ³• ====================
    
    async def get_content_calendar(
        self, 
        start_date: date = None, 
        end_date: date = None,
        status: str = None
    ) -> List[Dict[str, Any]]:
        """è·å–å†…å®¹æ—¥å†"""
        if start_date is None:
            start_date = date.today() - timedelta(days=7)
        if end_date is None:
            end_date = date.today() + timedelta(days=7)
        
        try:
            async with async_session_maker() as db:
                query = """
                    SELECT c.id, c.content_date, c.day_of_week, c.content_type, 
                           c.status, c.topic, c.generated_at, c.published_at,
                           COUNT(i.id) as item_count
                    FROM content_calendar c
                    LEFT JOIN content_items i ON c.id = i.calendar_id
                    WHERE c.content_date BETWEEN :start AND :end
                """
                params = {"start": start_date, "end": end_date}
                
                if status:
                    query += " AND c.status = :status"
                    params["status"] = status
                
                query += " GROUP BY c.id ORDER BY c.content_date DESC"
                
                result = await db.execute(text(query), params)
                rows = result.fetchall()
                
                return [
                    {
                        "id": str(row[0]),
                        "content_date": str(row[1]),
                        "day_of_week": row[2],
                        "content_type": row[3],
                        "content_name": self.CONTENT_SCHEDULE.get(row[2], {}).get("name", "æœªçŸ¥"),
                        "emoji": self.CONTENT_SCHEDULE.get(row[2], {}).get("emoji", "ğŸ“"),
                        "status": row[4],
                        "topic": row[5],
                        "generated_at": row[6].isoformat() if row[6] else None,
                        "published_at": row[7].isoformat() if row[7] else None,
                        "item_count": row[8]
                    }
                    for row in rows
                ]
        except Exception as e:
            logger.error(f"è·å–å†…å®¹æ—¥å†å¤±è´¥: {e}")
            return []
    
    async def get_content_items(self, calendar_id: str) -> List[Dict[str, Any]]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„å†…å®¹æ¡ç›®"""
        try:
            async with async_session_maker() as db:
                result = await db.execute(
                    text("""
                        SELECT id, platform, title, content, hashtags, 
                               call_to_action, video_script, status,
                               views, likes, comments, shares, leads_generated,
                               created_at
                        FROM content_items
                        WHERE calendar_id = :calendar_id
                        ORDER BY platform
                    """),
                    {"calendar_id": calendar_id}
                )
                rows = result.fetchall()
                
                return [
                    {
                        "id": str(row[0]),
                        "platform": row[1],
                        "platform_name": self.PLATFORM_NAMES.get(row[1], row[1]),
                        "title": row[2],
                        "content": row[3],
                        "hashtags": row[4] or [],
                        "call_to_action": row[5],
                        "video_script": row[6],
                        "status": row[7],
                        "stats": {
                            "views": row[8] or 0,
                            "likes": row[9] or 0,
                            "comments": row[10] or 0,
                            "shares": row[11] or 0,
                            "leads": row[12] or 0
                        },
                        "created_at": row[13].isoformat() if row[13] else None
                    }
                    for row in rows
                ]
        except Exception as e:
            logger.error(f"è·å–å†…å®¹æ¡ç›®å¤±è´¥: {e}")
            return []
    
    async def update_content_item(
        self, 
        item_id: str, 
        updates: Dict[str, Any]
    ) -> bool:
        """æ›´æ–°å†…å®¹æ¡ç›®"""
        try:
            async with async_session_maker() as db:
                set_parts = []
                params = {"id": item_id}
                
                for key, value in updates.items():
                    if key in ["title", "content", "call_to_action", "video_script", "status"]:
                        set_parts.append(f"{key} = :{key}")
                        params[key] = value
                    elif key == "hashtags":
                        set_parts.append("hashtags = :hashtags")
                        params["hashtags"] = value
                
                if set_parts:
                    set_parts.append("updated_at = NOW()")
                    query = f"UPDATE content_items SET {', '.join(set_parts)} WHERE id = :id"
                    await db.execute(text(query), params)
                    await db.commit()
                
                return True
        except Exception as e:
            logger.error(f"æ›´æ–°å†…å®¹æ¡ç›®å¤±è´¥: {e}")
            return False


# åˆ›å»ºæœåŠ¡å•ä¾‹
content_marketing_service = ContentMarketingService()
